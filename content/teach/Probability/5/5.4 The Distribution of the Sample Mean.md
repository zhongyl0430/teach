## 5.4 The Distribution of the Sample Mean

The importance of the sample mean $\bar{X}$ springs from its use in drawing conclusions about the population mean $\mu$ . Some of the most frequently used inferential procedures are based on properties of the sampling distribution of $\bar{X}$ . A preview of these properties appeared in the calculations and simulation experiments of the previous section, where we noted relationships between $E\left( \bar{X}\right)$ and $\mu$ and also among $V\left( \bar{X}\right) ,{\sigma }^{2}$ , and $n$ .

---

PROPOSITION

---

Let ${X}_{1},{X}_{2},\ldots ,{X}_{n}$ be a random sample from a distribution with mean value $\mu$ and standard deviation $\sigma$ . Then

1. $E\left( \bar{X}\right) = {\mu }_{\bar{X}} = \mu$

2. $V\left( \bar{X}\right) = {\sigma }_{\bar{X}}^{2} = {\sigma }^{2}/n$ and ${\sigma }_{\bar{X}} = \sigma /\sqrt{n}$

In addition, with ${T}_{o} = {\underline{X}}_{1} + \cdots + {\underline{X}}_{n}$ (the sample total), $E\left( {T}_{o}\right) = {n\mu }$ , $V\left( {T}_{o}\right) = n{\sigma }^{2}$ , and ${\sigma }_{{T}_{o}} = \sqrt{n}\sigma$ .

Proofs of these results are deferred to the next section. According to Result 1, the sampling (i.e., probability) distribution of $\bar{X}$ is centered precisely at the mean of the population from which the sample has been selected. Result 2 shows that the $\bar{X}$ distribution becomes more concentrated about $\mu$ as the sample size $n$ increases. In marked contrast, the distribution of ${T}_{o}$ becomes more spread out as $n$ increases. Averaging moves probability in toward the middle, whereas totaling spreads probability out over a wider and wider range of values. The standard deviation ${\sigma }_{\bar{x}} = \sigma /\sqrt{n}$ is often called the standard error of the mean; it describes the magnitude of a typical or representative deviation of the sample mean from the population mean.

5.25 In a notched tensile fatigue test on a titanium specimen, the expected number of cycles to first acoustic emission (used to indicate crack initiation) is $\mu = {28},{000}$ , and the standard deviation of the number of cycles is $\sigma = {5000}$ . Let ${X}_{1},{X}_{2},\ldots ,{X}_{25}$ be a random sample of size 25, where each ${X}_{i}$ is the number of cycles on a different randomly selected specimen. Then the expected value of the sample mean number of cycles until first emission is $E\left( \bar{X}\right) = \mu = {28},{000}$ , and the expected total number of cycles for the 25 specimens is $E\left( {T}_{0}\right) = {n\mu } = {25}\left( {{28},{000}}\right) = {700},{000}$ . The standard deviation of $\bar{X}$ (standard error of the mean) and of ${T}_{0}$ are

$$
{\sigma }_{\bar{X}} = \sigma /\sqrt{n} = \frac{5000}{\sqrt{25}} = {1000}
$$

$$
{\sigma }_{{T}_{o}} = \sqrt{n}\sigma = \sqrt{25}\left( {5000}\right) = {25},{000}
$$

If the sample size increases to $n = {100}, E\left( \bar{X}\right)$ is unchanged, but ${\sigma }_{\bar{X}} = {500}$ , half of its previous value (the sample size must be quadrupled to halve the standard deviation of $\bar{X}$ ).

### 5.4.1 The Case of a Normal Population Distribution

The simulation experiment of Example 5.23 indicated that when the population distribution is normal, a histogram of $\bar{x}$ values for any sample size $n$ is well approximated by a normal curve.

---

PROPOSITION

---

Let ${X}_{1},{X}_{2},\ldots ,{X}_{n}$ be a random sample from a normal distribution with mean $\mu$ and standard deviation $\sigma$ . Then for any $n,\bar{X}$ is normally distributed (with mean $\mu$ and standard deviation $\sigma /\sqrt{n}$ ), as is ${T}_{o}$ (with mean ${n\mu }$ and standard deviation $\sqrt{n}\sigma$ ).*

We know everything there is to know about the $\bar{X}$ and ${T}_{o}$ distributions when the population distribution is normal. In particular, probabilities such as $P\left( {a \leq \bar{X} \leq b}\right)$ and $P\left( {c \leq {T}_{o} \leq d}\right)$ can be obtained simply by standardizing. Figure 5.15 illustrates the $\bar{X}$ part of the proposition.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_33_675_1612_972_414_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_33_675_1612_972_414_0.jpg)

Figure 5.15 A normal population distribution and $\bar{X}$ sampling distributions

* A proof of the result for ${T}_{o}$ when $n = 2$ is possible using the method in Example 5.22, but the details are messy. The general result is usually proved using a theoretical tool called a moment generating function. One of the chapter references can be consulted for more information.

Copyright 2016 Congage Learning: All Rights Reserved, May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Congage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

EXAMPLE 5.26 The distribution of egg weights (g) of a certain type is normal with mean value 53 and standard deviation . 3 (consistent with data in the article "Evaluation of Egg Quality Traits of Chickens Reared under Backyard System in Western Uttar Pradesh" (Indian J. of Poultry Sci., 2009: 261-262)). Let ${X}_{1},{X}_{2},\ldots ,{X}_{12}$ denote the weights of a dozen randomly selected eggs; these ${X}_{i}$ ’s constitute a random sample of size 12 from the specified normal distribution.

The total weight of the 12 eggs is ${T}_{o} = {X}_{1} + \ldots + {X}_{12}$ ; it is normally distributed with mean value $E\left( {T}_{o}\right) = {n\mu } = {12}\left( {53}\right) = {636}$ and variance $V\left( {T}_{o}\right) = n{\sigma }^{2} = {12}{\left( {.3}\right) }^{2} =$ 1.08. The probability that the total weight is between 635 and 640 is now obtained by standardizing and referring to Appendix Table A.3:

$$
P\left( {{635} < {T}_{o} < {640}}\right) = \left( {\frac{{635} - {636}}{\sqrt{1.08}} < Z < \frac{{640} - {636}}{\sqrt{1.08}}}\right) = P\left( {-{.96} < Z < {3.85}}\right)
$$

$$
= \Phi \left( {3.85}\right) - \Phi \left( {-{.96}}\right) \approx 1 - {.1685} = {.8315}
$$

If cartons containing a dozen eggs are repeatedly selected, in the long run slightly more than ${83}\%$ of the eggs in a carton will weigh in total between ${635}\mathrm{\;g}$ and ${640}\mathrm{\;g}$ . Notice that ${635} < {T}_{o} < {640}$ is equivalent to ${52.9167} < \bar{X} < {53.3333}$ (divide each term in the original system of inequalities by 12). Thus $P\left( {{52.9167} < \bar{X} < {53.3333}}\right) \approx$ .8315. This latter probability can also be obtained by standardizing $\bar{X}$ directly.

Now consider randomly selecting just four of these eggs. The sample mean weight $\bar{X}$ is then normally distributed with mean value ${\mu }_{\bar{X}} = \mu = {53}$ and standard deviation ${\sigma }_{\bar{X}} = \sigma /\sqrt{n} = {.3}/\sqrt{4} = {.15}$ . The probability that the sample mean weight exceeds ${53.5}\mathrm{\;g}$ is then

$$
P\left( {\bar{X} > {53.5}}\right) = P\left( {Z > \frac{{53.5} - {53}}{.15}}\right)
$$

$$
= P\left( {Z > {3.33}}\right) = 1 - \Phi \left( {3.33}\right) = 1 - {.9996} = {.0004}
$$

Because 53.5 is 3.33 standard deviations (of $\bar{X}$ ) larger than the mean value 53, it is exceedingly unlikely that the sample mean will exceed 53.5.

### 5.4.2 The Central Limit Theorem

When the ${X}_{i}$ ’s are normally distributed, so is $\bar{X}$ for every sample size $n$ . The derivations in Example 5.21 and simulation experiment of Example 5.24 suggest that even when the population distribution is highly nonnormal, averaging produces a distribution more bell-shaped than the one being sampled. A reasonable conjecture is that if $n$ is large, a suitable normal curve will approximate the actual distribution of $\bar{X}$ . The formal statement of this result is the most important theorem of probability.

THEOREM

The Central Limit Theorem (CLT)

Let ${X}_{1},{X}_{2},\ldots ,{X}_{n}$ be a random sample from a distribution with mean $\mu$ and variance ${\sigma }^{2}$ . Then if $n$ is sufficiently large, $\bar{X}$ has approximately a normal distribution with ${\mu }_{\bar{X}} = \mu$ and ${\sigma }_{\bar{X}}^{2} = {\sigma }^{2}/n$ , and ${T}_{o}$ also has approximately a normal distribution with ${\mu }_{{T}_{o}} = {n\mu },{\sigma }_{{T}_{o}}^{2} = n{\sigma }^{2}$ . The larger the value of $n$ , the better the approximation.

Figure 5.16 illustrates the Central Limit Theorem. According to the CLT, when $n$ is large and we wish to calculate a probability such as $P\left( {a \leq \bar{X} \leq b}\right)$ , we need only "pretend" that $\bar{X}$ is normal, standardize it, and use the normal table. The resulting

![0192609f-6f5c-74c9-8588-c1ef28b2184d_35_817_176_760_409_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_35_817_176_760_409_0.jpg)

Figure 5.16 The Central Limit Theorem illustrated

answer will be approximately correct. The exact answer could be obtained only by first finding the distribution of $\bar{X}$ , so the CLT provides a truly impressive shortcut. The proof of the theorem involves much advanced mathematics.

EXAMPLE 5.27 The amount of a particular impurity in a batch of a certain chemical product is a random variable with mean value ${4.0}\mathrm{\;g}$ and standard deviation ${1.5}\mathrm{\;g}$ . If 50 batches are independently prepared, what is the (approximate) probability that the sample average amount of impurity $\bar{X}$ is between 3.5 and ${3.8}\mathrm{\;g}$ ? According to the rule of thumb to be stated shortly, $n = {50}$ is large enough for the CLT to be applicable. $\bar{X}$ then has approximately a normal distribution with mean value ${\mu }_{\bar{X}} = {4.0}$ and ${\sigma }_{\bar{X}} = {1.5}/\sqrt{50} = {.2121}$ , so

$$
P\left( {{3.5} \leq \bar{X} \leq {3.8}}\right) \approx P\left( {\frac{{3.5} - {4.0}}{.2121} \leq Z \leq \frac{{3.8} - {4.0}}{.2121}}\right)
$$

$$
= \Phi \left( {-{.94}}\right) - \Phi \left( {-{2.36}}\right) = {.1645}
$$

Now consider randomly selecting 100 batches, and let ${T}_{o}$ represent the total amount of impurity in these batches. Then the mean value and standard deviation of ${T}_{o}$ are ${100}\left( 4\right) = {400}$ and $\sqrt{100}\left( {1.5}\right) = {15}$ , respectively, and the CLT implies that ${T}_{0}$ has approximately a normal distribution. The probability that this total is at most ${425}\mathrm{\;g}$ is

$$
P\left( {{T}_{0} \leq {425}}\right) \approx P\left( {Z \leq \frac{{425} - {400}}{15}}\right) = P\left( {Z \leq {1.67}}\right) = \Phi \left( {1.67}\right) = {.9525}
$$

EXAMPLE 5.28 Let $X =$ the number of different people sent text messages during a particular day by a randomly selected student at a large university. Suppose the mean value of $X$ is 7 and the standard deviation is 6 (values very close to those reported in the article "Cell Phone Use and Grade Point Average Among Undergraduate University Students" (College Student J., 2011: 544-551). Among 100 randomly selected such students, how likely is it that the sample mean number of different people texted exceeds 5 ? Notice that the distribution being sampled is discrete, but the CLT is applicable whether the variable of interest is discrete or continuous. Also, although the fact that the standard deviation of this nonnegative variable is quite large relative to the mean value suggests that its distribution is positively skewed, the large sample size implies that $\bar{X}$ does have approximately a normal distribution. Using ${\mu }_{\bar{X}} = 7$ and ${\sigma }_{\bar{X}} = {.6}$ ,

$$
P\left( {\bar{X} > 5}\right) \approx P\left( {Z > \frac{5 - 7}{.6}}\right) = 1 - \Phi \left( {-{3.33}}\right) = {.9996}
$$

---

Note: The cited article stated that text messaging frequency was negatively correlated with GPA.

---

The CLT provides insight into why many random variables have probability distributions that are approximately normal. For example, the measurement error in a scientific experiment can be thought of as the sum of a number of underlying perturbations and errors of small magnitude.

A practical difficulty in applying the CLT is in knowing when $n$ is sufficiently large. The problem is that the accuracy of the approximation for a particular $n$ depends on the shape of the original underlying distribution being sampled. If the underlying distribution is close to a normal density curve, then the approximation will be good even for a small $n$ , whereas if it is far from being normal, then a large $n$ will be required.

Rule of Thumb

The Central Limit Theorem can generally be used if $n > {30}$ .

There are population distributions for which even an $n$ of 40 or 50 does not suffice, but such distributions are rarely encountered in practice. On the other hand, the rule of thumb is often conservative; for many population distributions, an $n$ much less than 30 would suffice. For example, in the case of a uniform population distribution, the CLT gives a good approximation for $n \geq {12}$ .

EXAMPLE 5.29 Consider the distribution shown in Figure 5.17 for the amount purchased (rounded to the nearest dollar) by a randomly selected customer at a particular gas station (a similar distribution for purchases in Britain (in $\pounds$ ) appeared in the article "Data Mining for Fun and Profit," Statistical Science, 2000: 111-131; there were big spikes at the values, ${10},{15},{20},{25}$ , and 30). The distribution is obviously quite non-normal.

We asked Minitab to select 1000 different samples, each consisting of $n = {15}$ observations, and calculate the value of the sample mean $\bar{X}$ for each one. Figure 5.18 is a histogram of the resulting 1000 values; this is the approximate

![0192609f-6f5c-74c9-8588-c1ef28b2184d_36_211_1481_1434_752_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_36_211_1481_1434_752_0.jpg)

![0192609f-6f5c-74c9-8588-c1ef28b2184d_37_690_182_1028_433_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_37_690_182_1028_433_0.jpg)

Figure 5.18 Approximate sampling distribution of the sample mean amount purchased when $n = {15}$ and the population distribution is as shown in Figure 5.17

sampling distribution of $\bar{X}$ under the specified circumstances. This distribution is clearly approximately normal even though the sample size is actually much smaller than 30, our rule-of-thumb cutoff for invoking the Central Limit Theorem. As further evidence for normality, Figure 5.19 shows a normal probability plot of the ${1000}\bar{x}$ values; the linear pattern is very prominent. It is typically not nonnormality in the central part of the population distribution that causes the CLT to fail, but instead very substantial skewness.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_37_770_1032_882_599_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_37_770_1032_882_599_0.jpg)

Figure 5.19 Normal probability plot from Minitab of the ${1000}\bar{x}$ values based on samples of size $n = {15}$

### 5.4.3 Other Applications of the Central Limit Theorem

The CLT can be used to justify the normal approximation to the binomial distribution discussed in Chapter 4. Recall that a binomial variable $X$ is the number of successes in a binomial experiment consisting of $n$ independent success/failure trials with $p = P\left( S\right)$ for any particular trial. Define a new $\mathrm{{rv}}{X}_{1}$ by

$$
{X}_{1} = \left\{ \begin{array}{ll} 1 & \text{ if the 1st trial results in a success } \\ 0 & \text{ if the 1st trial results in a failure } \end{array}\right.
$$

and define ${X}_{2},{X}_{3},\ldots ,{X}_{n}$ analogously for the other $n - 1$ trials. Each ${X}_{i}$ indicates whether or not there is a success on the corresponding trial.

Because the trials are independent and $P\left( S\right)$ is constant from trial to trial, the ${X}_{i}$ ’s are iid (a random sample from a Bernoulli distribution). The CLT then implies that if $n$ is sufficiently large, both the sum and the average of the ${X}_{i}$ ’s have approximately normal distributions. When the ${X}_{i}$ ’s are summed, a 1 is added for every $S$ that occurs and a 0 for every $F$ , so ${X}_{1} + \cdots + {X}_{n} = X$ . The sample mean of the ${X}_{i}$ ’s is $X/n$ , the sample proportion of successes. That is, both $X$ and $X/n$ are approximately normal when $n$ is large. The necessary sample size for this approximation depends on the value of $p$ : When $p$ is close to .5, the distribution of each ${X}_{i}$ is reasonably symmetric (see Figure 5.20), whereas the distribution is quite skewed when $p$ is near 0 or 1 . Using the approximation only if both ${np} \geq {10}$ and $n\left( {1 - p}\right) \geq {10}$ ensures that $n$ is large enough to overcome any skewness in the underlying Bernoulli distribution.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_38_837_675_566_214_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_38_837_675_566_214_0.jpg)

Figure 5.20 Two Bernoulli distributions: (a) $p = {.4}$ (reasonably symmetric); (b) $p = {.1}$ (very skewed)

Consider $n$ independent Poisson rv’s ${X}_{1},\ldots ,{X}_{n}$ , each having mean value $\mu /n$ . It can be shown that $X = {X}_{1} + \cdots + {X}_{n}$ has a Poisson distribution with mean value $\mu$ (because in general a sum of independent Poisson rv's has a Poisson distribution). The CLT then implies that a Poisson rv with sufficiently large $\mu$ has approximately a normal distribution. A common rule of thumb for this is $\mu > {20}$ .

Lastly, recall from Section 4.5 that $X$ has a lognormal distribution if $\ln \left( X\right)$ has a normal distribution. Let ${X}_{1},{X}_{2},\ldots ,{X}_{n}$ be a random sample from a distribution for which only positive values are possible $\left\lbrack {P\left( {{X}_{i} > 0}\right) = 1}\right\rbrack$ . Then if $n$ is sufficiently large, the product $Y = {X}_{1}{X}_{2}\cdots \cdots {X}_{n}$ has approximately a lognormal distribution.

To verify this, note that

$$
\ln \left( Y\right) = \ln \left( {X}_{1}\right) + \ln \left( {X}_{2}\right) + \cdots + \ln \left( {X}_{n}\right)
$$

Since $\ln \left( Y\right)$ is a sum of independent and identically distributed rv’s [the $\ln \left( {X}_{i}\right)$ ’s], it is approximately normal when $n$ is large, so $Y$ itself has approximately a lognormal distribution. As an example of the applicability of this result, Bury (Statistical Models in Applied Science, Wiley, p. 590) argues that the damage process in plastic flow and crack propagation is a multiplicative process, so that variables such as percentage elongation and rupture strength have approximately lognormal distributions.

### EXERCISES Section 5.4 (46-57)

46. Young's modulus is a quantitative measure of stiffness of an elastic material. Suppose that for aluminum alloy sheets of a particular type, its mean value and standard deviation are ${70}\mathrm{{GPa}}$ and ${1.6}\mathrm{{GPa}}$ , respectively (values given in the article "Influence of Material Properties Variability on Springback and Thinning in Sheet

Stamping Processes: A Stochastic Analysis" (Intl. J. of Advanced Manuf. Tech., 2010: 117-134)).

a. If $\bar{X}$ is the sample mean Young’s modulus for a random sample of $n = {16}$ sheets, where is the sampling distribution of $\bar{X}$ centered, and what is the standard deviation of the $\bar{X}$ distribution?

b. Answer the questions posed in part (a) for a sample size of $n = {64}$ sheets.

c. For which of the two random samples, the one of part (a) or the one of part (b), is $\bar{X}$ more likely to be within $1\mathrm{{GPa}}$ of ${70}\mathrm{{GPa}}$ ? Explain your reasoning.

47. Refer to Exercise 46. Suppose the distribution is normal (the cited article makes that assumption and even includes the corresponding normal density curve).

a. Calculate $P\left( {{69} \leq \bar{X} \leq {71}}\right)$ when $n = {16}$ .

b. How likely is it that the sample mean diameter exceeds 71 when $n = {25}$ ?

48. The National Health Statistics Reports dated Oct. 22, 2008, stated that for a sample size of 27718-year-old American males, the sample mean waist circumference was ${86.3}\mathrm{\;{cm}}$ . A somewhat complicated method was used to estimate various population percentiles, resulting in the following values: $\begin{array}{lllllll} {5}^{\text{th }} & {10}^{\text{th }} & {25}^{\text{th }} & {50}^{\text{th }} & {75}^{\text{th }} & {90}^{\text{th }} & {95}^{\text{th }} \end{array}$ $\begin{array}{lllllll} {69.6} & {70.9} & {75.2} & {81.3} & {95.4} & {107.1} & {116.4} \end{array}$

a. Is it plausible that the waist size distribution is at least approximately normal? Explain your reasoning. If your answer is no, conjecture the shape of the population distribution.

b. Suppose that the population mean waist size is ${85}\mathrm{\;{cm}}$ and that the population standard deviation is ${15}\mathrm{\;{cm}}$ . How likely is it that a random sample of 277 individuals will result in a sample mean waist size of at least ${86.3}\mathrm{\;{cm}}$ ?

c. Referring back to (b), suppose now that the population mean waist size in ${82}\mathrm{\;{cm}}$ . Now what is the (approximate) probability that the sample mean will be at least ${86.3}\mathrm{\;{cm}}$ ? In light of this calculation, do you think that ${82}\mathrm{\;{cm}}$ is a reasonable value for $\mu$ ?

49. There are 40 students in an elementary statistics class. On the basis of years of experience, the instructor knows that the time needed to grade a randomly chosen first examination paper is a random variable with an expected value of $6\mathrm{\;{min}}$ and a standard deviation of $6\mathrm{\;{min}}$ .

a. If grading times are independent and the instructor begins grading at $6 : {50}$ P.M. and grades continuously, what is the (approximate) probability that he is through grading before the ${11} : {00}$ P.M. TV news begins?

b. If the sports report begins at 11:10, what is the probability that he misses part of the report if he waits until grading is done before turning on the TV?

50. Let $X$ denote the courtship time for a randomly selected female-male pair of mating scorpion flies (time from the beginning of interaction until mating). Suppose the mean value of $X$ is ${120}\mathrm{\;{min}}$ and the standard deviation of $X$ is 110 min (suggested by data in the article "Should I Stay or Should I Go? Condition- and Status-Dependent Courtship Decisions in the Scorpion Fly Panorpa Cognate" (Animal Behavior, 2009: 491-497)).

a. Is it plausible that $X$ is normally distributed?

b. For a random sample of 50 such pairs, what is the (approximate) probability that the sample mean courtship time is between ${100}\mathrm{\;{min}}$ and ${125}\mathrm{\;{min}}$ ?

c. For a random sample of 50 such pairs, what is the (approximate) probability that the total courtship time exceeds ${150}\mathrm{{hr}}$ ?

d. Could the probability requested in (b) be calculated from the given information if the sample size were 15 rather than 50 ? Explain.

51. The time taken by a randomly selected applicant for a mortgage to fill out a certain form has a normal distribution with mean value ${10}\mathrm{\;{min}}$ and standard deviation 2 min. If five individuals fill out a form on one day and six on another, what is the probability that the sample average amount of time taken on each day is at most ${11}\mathrm{\;{min}}$ ?

52. The lifetime of a certain type of battery is normally distributed with mean value 10 hours and standard deviation 1 hour. There are four batteries in a package. What lifetime value is such that the total lifetime of all batteries in a package exceeds that value for only $5\%$ of all packages?

53. Rockwell hardness of pins of a certain type is known to have a mean value of 50 and a standard deviation of 1.2 .

a. If the distribution is normal, what is the probability that the sample mean hardness for a random sample of 9 pins is at least 51 ?

b. Without assuming population normality, what is the (approximate) probability that the sample mean hardness for a random sample of 40 pins is at least 51?

54. Suppose the sediment density $\left( {\mathrm{g}/\mathrm{{cm}}}\right)$ of a randomly selected specimen from a certain region is normally distributed with mean 2.65 and standard deviation .85 (suggested in “Modeling Sediment and Water Column Interactions for Hydrophobic Pollutants," Water Research, 1984: 1169-1174).

a. If a random sample of 25 specimens is selected, what is the probability that the sample average sediment density is at most 3.00 ? Between 2.65 and 3.00 ?

b. How large a sample size would be required to ensure that the first probability in part (a) is at least .99 ?

55. The number of parking tickets issued in a certain city on any given weekday has a Poisson distribution with parameter $\mu = {50}$ .

a. Calculate the approximate probability that between 35 and 70 tickets are given out on a particular day.

b. Calculate the approximate probability that the total number of tickets given out during a 5-day week is between 225 and 275.

c. Use software to obtain the exact probabilities in (a) and (b) and compare to their approximations.

56. A binary communication channel transmits a sequence of "bits" (0s and 1s). Suppose that for any particular bit transmitted, there is a ${10}\%$ chance of a transmission error (a 0 becoming a 1 or a 1 becoming a 0 ). Assume that bit errors occur independently of one another.

a. Consider transmitting 1000 bits. What is the approximate probability that at most 125 transmission errors occur?

b. Suppose the same 1000-bit message is sent two different times independently of one another. What is the approximate probability that the number of errors in the first transmission is within 50 of the number of errors in the second?

57. Suppose the distribution of the time $X$ (in hours) spent by students at a certain university on a particular project is gamma with parameters $\alpha = {50}$ and $\beta = 2$ . Because $\alpha$ is large, it can be shown that $X$ has approximately a normal distribution. Use this fact to compute the approximate probability that a randomly selected student spends at most 125 hours on the project.