在这一节中，我们假设训练样本 $S$ 可以线性分离，也就是说，我们假设存在一个超平面，能够完美地将训练样本分离成两个分别标记为正负的点集，如图5.1左侧面板所示。这等同于存在 $\left( {\mathbf{w}, b}\right) \in \left( {{\mathbb{R}}^{N}-\{ \mathbf{0}\} }\right) \times \mathbb{R}$ 使得
$$
\forall i \in \left\lbrack m\right\rbrack ,\;{y}_{i}\left( {\mathbf{w} \cdot {\mathbf{x}}_{i} + b}\right) \geq 0. \tag{5.3}
$$

但如图5.1所示，存在无限多个这样的分离超平面。学习算法应该选择哪一个超平面呢？SVM解决方案的定义基于几何边缘的概念。

定义5.1(几何边缘)线性分类器 $h : \mathbf{x} \mapsto \mathbf{w} \cdot \mathbf{x} + b$ 在点 $\mathbf{x}$ 的几何边缘 ${\rho }_{h}\left( \mathbf{x}\right)$ 是它到超平面 $\mathbf{w} \cdot \mathbf{x} + b = 0$ 的欧氏距离:

$$
{\rho }_{h}\left( x\right) = \frac{\left| \mathbf{w} \cdot \mathbf{x} + b\right| }{\parallel \mathbf{w}{\parallel }_{2}}. \tag{5.4}
$$

线性分类器 $h$ 对于样本 $S = \left( {{\mathbf{x}}_{1},\ldots ,{\mathbf{x}}_{m}}\right)$ 的几何边缘 ${\rho }_{h}$ 是样本点上的最小几何边缘 ${\rho }_{h} = \mathop{\min }\limits_{{i \in \left\lbrack m\right\rbrack }}{\rho }_{h}\left( {x}_{i}\right)$ ，即定义 $h$ 的超平面到最近样本点的距离。

SVM解决方案是具有最大几何间隔的分隔超平面，因此被称为最大间隔超平面。图5.1右面板展示了在可分情况下SVM算法返回的最大间隔超平面。在本章后面，我们将介绍一个理论，为这个解决方案提供有力的证明。然而，我们目前已经可以观察到，SVM解决方案也可以被视为在以下意义上“最安全”的选择:即使测试点落在与具有相同标签的训练样本的距离$\rho$内，分隔超平面也能以几何间隔$\rho$正确分类测试点；对于SVM解决方案，$\rho$是最大几何间隔，因此是最“安全”的值。

![0192515b-435f-75ef-9b27-37409ba7b98f_2_610_242_585_446_0.jpg](images/0192515b-435f-75ef-9b27-37409ba7b98f_2_610_242_585_446_0.jpg)

图5.2

点$\mathbf{x}$在情况$\mathbf{w} \cdot \mathbf{x} > 0$和$b > 0$下的几何间隔示例。

[[5.2.1 原始优化问题]]

[[5.2.2 支持向量]]

[[5.2.3 对偶优化问题]]

[[5.2.4 留一法分析]]