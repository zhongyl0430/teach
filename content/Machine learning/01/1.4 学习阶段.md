---
tags:
  - "#teach/ML"
---
* 使用垃圾邮件检测的典型问题作为一个运行示例：
* 垃圾邮件检测是一个学习自动将电子邮件消息分类为垃圾邮件或非垃圾邮件的问题。

* 以下是在机器学习中常用的定义和术语列表：
---
- **示例 (example)**
	- 用于学习或评估的数据项或实例。
	- 我们将用于学习和测试的电子邮件消息集合。
---
- **特征 (feature)**
	- 与示例相关的一组属性，通常表示为向量。
	- 一些相关特征可能包括
		- 消息长度
		- 发件人名称、标题的各种特征
		- 消息正文中某些关键词的出现
---
- **标签 (label)**
	- 分配给示例的值或类别。
	- 分类问题中：示例被分配特定的类别
		- 垃圾邮件和非垃圾邮件类别
	- 回归问题中：项目被分配实值标签。

- **超参数 (hyperparameter)**
	- 不由学习算法确定的自由参数，而是作为学习算法的输入指定的。
---
- **训练样本 (training sample)**
	- 用于训练学习算法的示例。
	- 一组电子邮件示例及其相关标签组成
	- 训练样本会根据不同学习场景而有所不同。
---
- **验证样本 (validation sample)**
	- 在有标签数据上调整学习算法参数时使用的示例。
	- 用于选择学习算法自由参数（超参数）的合适值。
---
- **测试样本 (test sample)**
	- 用于评估学习算法性能的示例。
	- 测试样本独立于训练和验证数据，在学习阶段不可用
	- 在垃圾邮件问题中，测试样本由一组电子邮件示例组成，学习算法必须根据特征预测这些示例的标签。然后将这些预测与测试样本的标签进行比较，以衡量算法的性能。
---
- **损失函数 (loss function)**
	- 一个衡量预测标签和真实标签之间差异（或损失）的函数。
	- 设所有标签的集合为 $\mathcal{Y}$
	- 可能的预测集合为 $\mathcal{Y}'$ 
	- 损失函数 $L$ 是一个映射 $L : \mathcal{Y} \times \mathcal{Y}' \rightarrow {\mathbb{R}}_{+}$ 
	- 在大多数情况下， ${y}^{\prime } = y$ 且损失函数有界
---

- 损失函数的常见例子
	- 在 $\{ - 1, + 1\} \times \{ - 1, + 1\}$ 上定义的**零一 / 误分类损失 (zero-one / misclassification error)** $L\left( {y,{y}^{\prime }}\right) = {1}_{{y}^{\prime } \neq y}$ 
	- 在 $\mathcal{J} \times \mathcal{J}$ 上定义的**平方损失 (squared loss)** $L\left( {y,{y}^{\prime }}\right) = {\left( {y}^{\prime } - y\right) }^{2}$ ，其中 $\mathcal{J} \subseteq \mathbb{R}$ 通常是一个有界区间。
---
- **假设集 (hypothesis set)**
	- 一组将特征（特征向量）映射到标签集合 $\mathcal{Y}$ 的函数 
	- 一组将电子邮件特征映射到 $\mathcal{Y} = \{$ 垃圾邮件，非垃圾邮件 $\}$ 的函数。
	- 更一般地，假设可能是将特征映射到另一个集合 $\mathcal{Y}'$ 的函数 。
	- 将电子邮件特征向量映射到实数的线性函数，这些实数被解释为分数 $\left( {{\mathcal{Y}}^{\prime } = \mathbb{R}}\right)$ ，分数值越高，表明垃圾邮件的可能性越大。
---
> ![01917e5a-246e-7afb-b594-9077a1d7cfd5_5_594567.jpg](images/01917e5a-246e-7afb-b594-9077a1d7cfd5_5_594567.jpg)
> 图1.1 学习过程典型阶段的示意图。 ^fig-1-1

---
定义垃圾邮件问题的学习阶段：

1. 我们从给定的标记示例集合开始。
	- 随机地将数据划分为
		- 训练样本
		- 验证样本
		- 测试样本
	- 这些样本的大小取决于多种不同的考虑因素。
		- 为验证保留的数据量取决于算法的超参数数量，这里由向量 $\Theta$ 表示。
		- 当标记样本相对较小时，通常选择比测试数据更多的训练数据，因为学习性能直接依赖于训练样本。
---
2. 我们将相关特征与示例相关联
	- 这是机器学习解决方案设计中关键的一步
	- 有用的特征可以有效地指导学习算法，而糟糕的或不提供信息的特征可能会产生误导
	- 尽管这非常关键，但在很大程度上，特征的选择留给了用户
	- 这个选择反映了用户对学习任务的先验知识，这在实践中可能对性能结果产生巨大的影响。
---
3. 我们使用选择的特征来通过调整其自由参数（也称为超参数） $\Theta$ 的值来训练我们的学习算法 $\mathcal{A}$。
	- 对于这些参数的每个值，算法从假设集中选择一个不同的假设。
	- 我们选择在验证样本上 $\left( {\Theta }_{0}\right)$ 表现最佳的假设。
	- 最后，使用该假设，我们预测测试样本中例子的标签。
	- 算法的性能通过使用与任务关联的损失函数来评估
		- 在我们的垃圾邮件检测任务中使用零一损失来比较预测标签和真实标签。
	- 因此，算法的性能当然是基于其测试错误而不是训练样本上的错误来评估的。
---