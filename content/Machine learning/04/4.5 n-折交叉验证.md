在实际中，可用的标记数据量通常太小，无法留出验证样本，因为这会导致训练数据不足。相反，广泛采用的一种称为n折交叉验证的方法被用来充分利用标记数据，既用于模型选择，也用于训练。

- 令 $\mathbf{\theta}$ 表示算法的自由参数向量
  - 对于 $\mathbf{\theta}$ 的一个固定值
    - 将给定的样本 $S$ 中的 $m$ 个标记示例随机划分为 $n$ 个子样本或折
      - 第 $i$ 个折是一个大小为 ${m}_{i}$ 的标记样本
        - 形式为 $\left( {\left( {{x}_{i1},{y}_{i1}}\right), \ldots, \left( {{x}_{i{m}_{i}},{y}_{i{m}_{i}}}\right) }\right)$
  - 对于任意的 $i \in \left\lbrack n\right\rbrack$
    - 学习算法在除了第 $i$ 个折之外的所有数据上训练
      - 生成假设 ${h}_{i}$
      - 如图 4.5a 所示，$ {h}_{i}$ 的性能在第 $i$ 个折上进行测试
  - 参数值 $\mathbf{\theta}$ 根据 ${h}_{i}$ 的假设的平均错误来评估
    - 这个错误称为交叉验证误差
    - 用 ${\widehat{R}}_{\mathrm{{CV}}}\left( \mathbf{\theta }\right)$ 表示并定义为

$$
{\widehat{R}}_{\mathrm{{CV}}}\left( \mathbf{\theta }\right) = \frac{1}{n}\mathop{\sum }\limits_{{i = 1}}^{n}\underset{\text{error of }{h}_{i}\text{ on the }i\text{th fold }}{\underbrace{\frac{1}{{m}_{i}}\mathop{\sum }\limits_{{j = 1}}^{{m}_{i}}L\left( {{h}_{i}\left( {x}_{ij}\right) ,{y}_{ij}}\right) }}.
$$

- 通常选择折数大小相等，即 ${m}_{i} = m/n$ 对于所有 $i \in \left\lbrack n\right\rbrack$
- 如何选择 $n$？
  - 合适的选择需要权衡
    - 较大的 $n$：
      - 每个训练样本的大小为 $m - m/n = m(1 - 1/n)$
        - 接近于 $m$，即完整样本的大小
        - 所有训练样本相似
      - 第 $i$ 折用于测量误差相对较小
        - 交叉验证误差具有较小的偏差但较大的方差
    - 较小的 $n$：
      - 训练样本更多样化
      - 样本大小明显小于 $m$
        - 第 $i$ 折相对较大
      - 交叉验证误差具有较小的方差但较大的偏差

- 在实际应用中，$n$ 通常选择为 5 或 10
- $n$-折交叉验证在模型选择中的使用：
  - 首先将完整的标记数据分为训练样本和测试样本
  - 大小为 $m$ 的训练样本用于计算 $n$-折交叉验证误差 ${\widehat{R}}_{\mathrm{{CV}}}\left( \mathbf{\theta }\right)$
    - 针对少量可能的 $\mathbf{\theta}$ 值
  - 自由参数 $\mathbf{\theta}$ 设置为使 ${\widehat{R}}_{\mathrm{{CV}}}\left( \mathbf{\theta }\right)$ 最小的值 ${\mathbf{\theta }}_{0}$
  - 使用参数设置 ${\mathbf{\theta }}_{0}$ 在大小为 $m$ 的完整训练样本上训练算法
    - 其性能通过测试样本进行评估

- $n$-重交叉验证的特殊情况：
  - $n = m$ 被称为留一交叉验证
    - 每次迭代恰好有一个实例被留出训练集的样本
  - 留一法的平均误差：
    - 是对算法平均误差的无偏估计
    - 可以为某些算法导出简单的保证
  - 留一法的计算成本：
    - 一般来说，计算成本很高
      - 需要在大小为 $m - 1$ 的样本上训练 $m$ 次
    - 对于某些算法，计算效率非常高（见练习 11.9）


图 4.5
$n$-重交叉验证。 
(a) 将训练数据划分为 5 折的示意图。 
(b) 分类器的预测误差随训练样本大小$m$变化的典型曲线:误差随训练点数的增加而减小。
左侧的红色线条标记了$n$值较小的区域，而右侧的红色线条标记了$n$值较大的区域。
![01924b36-62e2-7d6a-9feb-ac32232c9804_11_459_275_900_392_0.jpg](images/01924b36-62e2-7d6a-9feb-ac32232c9804_11_459_275_900_392_0.jpg)

- 除了模型选择之外，$n$-重交叉验证也常用于性能评估
  - 对于固定的参数设置 $\mathbf{\theta}$：
    - 整个标记样本被分为 $n$ 个随机折
      - 不区分训练集和测试集
  - 报告的性能：
    - 整个样本的 $n$-重交叉验证误差
    - 每个折上误差的标准差

