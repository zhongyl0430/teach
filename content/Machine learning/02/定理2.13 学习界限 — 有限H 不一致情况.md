
> [!theorem] 定理2.13 （学习界限 — 有限 $\mathcal{H}$ ，不一致情况）
> - 取 $\mathcal{H}$ 为一个有限的假设集。
> - 那么，
> 	- 对于任何 $\delta > 0$ ，
> 	- 在至少 $1 - \delta$ 的概率下，
> 	- 以下不等式成立： $\forall h \in \mathcal{H},$
> $$R \left( h\right) \leq {\widehat{R}}_{S}\left( h\right) + \sqrt{\frac{\log \left| \mathcal{H}\right| + \log \frac{2}{\delta }}{2m}}. \tag{2.20}$$

---

`\begin{proof}`
令 ${h}_{1},\ldots ,{h}_{\left| \mathcal{H}\right| }$ 为 $\mathcal{H}$ 的元素。使用并集界限并将 [[#^cor-2-11|推论 2.11]] 应用于每个假设得到：
$$
\begin{align}
&\mathbb{P}\left\lbrack {\exists h \in \mathcal{H}\left| {{\widehat{R}}_{S}\left( h\right) - R\left( h\right) }\right| > \epsilon }\right\rbrack \\
= &\mathbb{P}\left\lbrack \right. \left( {\left| {{\widehat{R}}_{S}\left( {h}_{1}\right) - R\left( {h}_{1}\right) }\right| > \epsilon }\right) \vee \\
&\ldots \vee \left( {\left| {{\widehat{R}}_{S}\left( {h}_{\left| \mathcal{H}\right| }\right) - R\left( {h}_{\left| \mathcal{H}\right| }\right) }\right| > \epsilon }\right) \left. \right\rbrack \\
\leq &\mathop{\sum }\limits_{{h \in \mathcal{H}}}\mathbb{P}\left\lbrack {\left| {{\widehat{R}}_{S}\left( h\right) - R\left( h\right) }\right| > \epsilon }\right\rbrack \\
\leq &2\left| \mathcal{H}\right| \exp \left( {-{2m}{\epsilon }^{2}}\right)
\end{align}
$$
将右侧设置为等于 $\delta$ 完成证明。
`\end{proof}`

---

因此，对于有限的假设集 $\mathcal{H}$ ，
$$
R\left( h\right) \leq {\widehat{R}}_{S}\left( h\right) + O\left( \sqrt{\frac{{\log }_{2}\left| \mathcal{H}\right| }{m}}\right) .
$$
> [!remark]
> - 如前所述，${\log }_{2}\left| \mathcal{H}\right|$ 可以解释为表示 $\mathcal{H}$ 所需的位数。
> - 与一致情况下的泛化界限相关的其他几个类似评论也可以在这里提出：
> 	- 较大的样本大小 $m$ 保证更好的泛化，并且界限随 $\left| \mathcal{H}\right|$ 增加而增加，但仅以对数方式。
> - 但是，在这里，界限是 $\frac{{\log }_{2}\left| \mathcal{H}\right| }{m}$ 的一个较不利的函数；
> 	- 它与这个项的 *平方根* 成比例变化。
> 	- 这不是一个小的代价：对于固定的 $\left| \mathcal{H}\right|$， 要达到一致情况下的相同保证，需要的标记样本数量是平方级的增加。

---
$$
R\left( h\right) \leq {\widehat{R}}_{S}\left( h\right) + O\left( \sqrt{\frac{{\log }_{2}\left| \mathcal{H}\right| }{m}}\right) .
$$
> [!remark] 奥卡姆剃刀原则 (Occam's Razor principle)
> 这个界限建议在减少经验误差与控制假设集大小之间寻求平衡：
> - 较大的假设集会受到第二项的惩罚， 但可能有助于减少第一项经验误差。
> - 但是，在相似的经验误差下，它建议使用较小的假设集。
> 
> 这可以被视为所谓的奥卡姆剃刀原则的一个实例，该原则以神学家威廉·奥卡姆的名字命名：
> - 若无必要，不应假设多样，
> - 也可以重述为，最简单的解释是最好的。
> - 在这个背景下，它可以表达如下：在其他条件相同的情况下，更简单（更小）的假设集是更好的。
> - 回顾 [[1.6 泛化]] 的例子
