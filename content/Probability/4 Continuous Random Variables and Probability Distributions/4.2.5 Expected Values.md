For a discrete random variable $X$, $E\left( X\right)$ was obtained by summing $x \cdot p\left( x\right)$ over possible $X$ values. 
Here we replace summation by integration and the pmf by the pdf to get a continuous weighted average.

> [!definition] expected value
> The **expected or mean value** of a continuous rv $X$ with $\operatorname{pdf}f\left( x\right)$ is
> $$
> {\mu }_{X} = E\left( X\right) = {\int }_{-\infty }^{\infty }x \cdot f\left( x\right) {dx}
> $$

[[EX 4.10 expected value of EX 4.9]]

When the pdf $f\left( x\right)$ specifies a model for the distribution of values in a numerical population, then $\mu$ is the population mean, which is the most frequently used measure of population location or center.

Often we wish to compute the expected value of some function $h\left( X\right)$ of the rv $X$ . 
If we think of $h\left( X\right)$ as a new rv $Y$, techniques from mathematical statistics can be used to derive the pdf of $Y$, and $E\left( Y\right)$ can then be computed from the definition. 
Fortunately, as in the discrete case, there is an easier way to compute $E\left\lbrack {h\left( X\right) }\right\rbrack$ .

> [!proposition] expected value of function
> If $X$ is a continuous $\operatorname{rv}$ with $\operatorname{pdf}f\left( x\right)$ and $h\left( X\right)$ is any function of $X$, then
> $$
> E\left\lbrack {h\left( X\right) }\right\rbrack = {\mu }_{h\left( X\right) } = {\int }_{-\infty }^{\infty }h\left( x\right) \cdot f\left( x\right) {dx}
> $$

That is, just as $E\left( X\right)$ is a weighted average of possible $X$ values, where 
- the weighting function is the pdf $f\left( x\right)$, 
- $E\left\lbrack {h\left( X\right) }\right\rbrack$ is a weighted average of $h\left( X\right)$ values.

[[EX 4.11 expected value of max]]

In the discrete case, the variance of $X$ was defined as the expected squared deviation from $\mu$ and was calculated by summation. 
Here again integration replaces summation.

> [!definition] variance
> The **variance** of a continuous random variable $X$ with $\operatorname{pdf}f\left( x\right)$ and mean value $\mu$ is
> 
> $$
> \begin{align}
>     {\sigma }_{X}^{2} &= V\left( X \right) \\
>     &= \int_{-\infty}^{\infty} \left( x - \mu \right)^{2} \cdot f\left( x \right) \, dx \\
>     &= E\left[ \left( X - \mu \right)^{2} \right]
> \end{align}
> $$
> 
> The **standard deviation (SD)** of $X$ is $${\sigma }_{X} = \sqrt{V\left( X\right) } .$$

The variance and standard deviation give quantitative measures of how much spread there is in the distribution or population of $x$ values. 
Again $\sigma$ is roughly the size of a typical deviation from $\mu$. 
Computation of ${\sigma }^{2}$ is facilitated by using the same shortcut formula employed in the discrete case.

> [!proposition]
> $$
> V\left( X\right) = E\left( {X}^{2}\right) - {\left\lbrack E\left( X\right) \right\rbrack }^{2}
> $$

[[EX 4.12 EX 4.10 continued]]

[[Expected value and variance of linear function]]