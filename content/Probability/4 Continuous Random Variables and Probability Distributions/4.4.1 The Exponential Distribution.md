The family of exponential distributions provides probability models that are very widely used in engineering and science disciplines.

> [!definition] exponential distribution
> $X$ is said to have an **exponential distribution** with (scale) parameter $\lambda \left( {\lambda > 0}\right)$ if the pdf of $X$ is
> $$
> f\left( {x;\lambda }\right) = \left\{ \begin{matrix} \lambda {e}^{-{\lambda x}} & x \geq 0 \\ 0 & \text{ otherwise } \end{matrix}\right. \tag{4.5}
> $$

Some sources write the exponential pdf in the form $\left( {1/\beta }\right) {e}^{-x/\beta }$ , so that $\beta = 1/\lambda$ . 

The expected value of an exponentially distributed random variable $X$ is
$$
\mu = E\left( X\right) = {\int }_{0}^{\infty }{x\lambda }{e}^{-{\lambda x}}{dx}
$$

Obtaining this expected value necessitates doing an integration by parts. 
The variance of $X$ can be computed using the fact that $V\left( X\right) = E\left( {X}^{2}\right) - {\left\lbrack E\left( X\right) \right\rbrack }^{2}$. 
The determination of $E\left( {X}^{2}\right)$ requires integrating by parts twice in succession. 
The results of these integrations are as follows:
$$
\mu = \frac{1}{\lambda }\;{\sigma }^{2} = \frac{1}{{\lambda }^{2}}
$$

Both the mean and standard deviation of the exponential distribution equal $1/\lambda$ . 
Graphs of several exponential pdf's are illustrated in Figure 4.26.

Figure 4.26 
Exponential density curves
![01925166-48c0-7eca-9860-67f13d0848b1_30_937_184_519_389_0.jpg](images/01925166-48c0-7eca-9860-67f13d0848b1_30_937_184_519_389_0.jpg)

The exponential pdf is easily integrated to obtain the cdf.
$$
F\left( {x;\lambda }\right) = \left\{ \begin{matrix} 0 & x < 0 \\ 1 - {e}^{-{\lambda x}} & x \geq 0 \end{matrix}\right.
$$

The exponential distribution is frequently used as a model for the distribution of times between the occurrence of successive events, such as customers arriving at a service facility or calls coming in to a switchboard. 
The reason for this is that the exponential distribution is closely related to the Poisson process discussed in [[3.6 The Poisson Probability Distribution]].

> [!proposition] exponential distribution vs Poisson distribution
> Suppose that the number of events occurring in any time interval of length $t$ has a Poisson distribution with parameter ${\alpha t}$ (where $\alpha$ , the rate of the event process, is the expected number of events occurring in 1 unit of time) and that numbers of occurrences in nonoverlapping intervals are independent of one another. 
> Then the distribution of elapsed time between the occurrence of two successive events is exponential with parameter $\lambda = \alpha$ .

Although a complete proof is beyond the scope of the text, the result is easily verified for the time ${X}_{1}$ until the first event occurs:
$$
\begin{align}
    &P\left( X_{1} \leq t \right) \\
    &= 1 - P\left( X_{1} > t \right) \\
    &= 1 - P\left[ \text{no events in } \left( 0, t \right) \right] \\
    &= 1 - \frac{e^{-\alpha t} \cdot \left( \alpha t \right)^{0}}{0!} \\
    &= 1 - e^{-\alpha t}
\end{align}
$$
which is exactly the cdf of the exponential distribution.

[[EX 4.22]]

Another important application of the exponential distribution is to model the distribution of component lifetime. 
A partial reason for the popularity of such applications is the "memoryless" property of the exponential distribution. 
Suppose component lifetime is exponentially distributed with parameter $\lambda$. 
After putting the component into service, we leave for a period of ${t}_{0}$ hours and then return to find the component still working; what now is the probability that it lasts at least an additional $t$ hours? 
In symbols, we wish $P\left( {X \geq t + {t}_{0} \mid X \geq {t}_{0}}\right)$ . By the definition of conditional probability,
$$
\begin{align}
    &P\left( X \geq t + t_{0} \mid X \geq t_{0} \right) \\
    &= \frac{P\left[ \left( X \geq t + t_{0} \right) \cap \left( X \geq t_{0} \right) \right]}{P\left( X \geq t_{0} \right)}
\end{align}
$$

But the event $X \geq {t}_{0}$ in the numerator is redundant, since both events can occur if and only if $X \geq t + {t}_{0}$ . Therefore,
$$
\begin{align}
    &P\left( X \geq t + t_{0} \mid X \geq t_{0} \right) \\
    &= \frac{P\left( X \geq t + t_{0} \right)}{P\left( X \geq t_{0} \right)} \\
    &= \frac{1 - F\left( t + t_{0}; \lambda \right)}{1 - F\left( t_{0}; \lambda \right)} \\
    &= e^{-\lambda t}
\end{align}
$$

This conditional probability is identical to the original probability $P\left( {X \geq t}\right)$ that the component lasted $t$ hours. 
Thus the distribution of additional lifetime is exactly the same as the original distribution of lifetime, so at each point in time the component shows no effect of wear. 
In other words, the distribution of remaining lifetime is independent of current age.

Although the memoryless property can be justified at least approximately in many applied problems, in other situations components deteriorate with age or occasionally improve with age (at least up to a certain point). 
More general lifetime models are then furnished by the gamma, Weibull, and lognormal distributions (the latter two are discussed in the next section).