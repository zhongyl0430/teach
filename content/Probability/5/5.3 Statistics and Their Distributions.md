## 5.3 Statistics and Their Distributions

The observations in a single sample were denoted in Chapter 1 by ${x}_{1},{x}_{2},\ldots ,{x}_{n}$ . Consider selecting two different samples of size $n$ from the same population distribution. The ${x}_{i}$ ’s in the second sample will virtually always differ at least a bit from those in the first sample. For example, a first sample of $n = 3$ cars of a particular type might result in fuel efficiencies ${x}_{1} = {30.7},{x}_{2} = {29.4},{x}_{3} = {31.1}$ , whereas a second sample may give ${x}_{1} = {28.8},{x}_{2} = {30.0}$ , and ${x}_{3} = {32.5}$ . Before we obtain data, there is uncertainty about the value of each ${x}_{i}$ . Because of this uncertainty, before the data becomes available we now regard each observation as a random variable and denote the sample by ${X}_{1},{X}_{2},\ldots ,{X}_{n}$ (uppercase letters for random variables).

This variation in observed values in turn implies that the value of any function of the sample observations-such as the sample mean, sample standard deviation, or sample fourth spread-also varies from sample to sample. That is, prior to obtaining ${x}_{1},\ldots ,{x}_{n}$ , there is uncertainty as to the value of $\bar{x}$ , the value of $s$ , and so on.

EXAMPLE 5.20 Suppose that material strength for a randomly selected specimen of a particular type has a Weibull distribution with parameter values $\alpha = 2$ (shape) and $\beta = 5$ (scale). The corresponding density curve is shown in Figure 5.7. Formulas from Section 4.5 give

$$
\mu = E\left( X\right) = {4.4311}\;\widetilde{\mu } = {4.1628}\;{\sigma }^{2} = V\left( X\right) = {5.365}\;\sigma = {2.316}
$$

The mean exceeds the median because of the distribution's positive skew.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_22_778_1761_643_406_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_22_778_1761_643_406_0.jpg)

Figure 5.7 The Weibull density curve for Example 5.20

Copyright 2016 Cangage Learning: All Rights Reserved, May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Congage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

We used statistical software to generate six different samples, each with $n = {10}$ , from this distribution (material strengths for six different groups of ten specimens each). The results appear in Table 5.1, followed by the values of the sample mean, sample median, and sample standard deviation for each sample. Notice first that the ten observations in any particular sample are all different from those in any other sample. Second, the six values of the sample mean are all different from one another, as are the six values of the sample median and the six values of the sample standard deviation. The same is true of the sample ${10}\%$ trimmed means, sample fourth spreads, and so on. Furthermore, the value of the sample mean from any particular sample can be regarded as a point estimate ("point" because it is a single number, corresponding to a single point on the number line) of the population mean $\mu$ , whose value is known to be 4.4311 . None of the estimates from these six samples is identical to what is being estimated. The estimates from the second and sixth samples are much too large, whereas the fifth sample gives a substantial underestimate. Similarly, the sample standard deviation gives a point estimate of the population standard deviation. All six of the resulting estimates are in error by at least a small amount.

Table 5.1 Samples from the Weibull Distribution of Example 5.20

<table><thead><tr><th>Sample</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tr><td>1</td><td>6.1171</td><td>5.07611</td><td>3.46710</td><td>1.55601</td><td>3.12372</td><td>8.93795</td></tr><tr><td>2</td><td>4.1600</td><td>6.79279</td><td>2.71938</td><td>4.56941</td><td>6.09685</td><td>3.92487</td></tr><tr><td>3</td><td>3.1950</td><td>4.43259</td><td>5.88129</td><td>4.79870</td><td>3.41181</td><td>8.76202</td></tr><tr><td>4</td><td>0.6694</td><td>8.55752</td><td>5.14915</td><td>2.49759</td><td>1.65409</td><td>7.05569</td></tr><tr><td>5</td><td>1.8552</td><td>6.82487</td><td>4.99635</td><td>2.33267</td><td>2.29512</td><td>2.30932</td></tr><tr><td>6</td><td>5.2316</td><td>7.39958</td><td>5.86887</td><td>4.01295</td><td>2.12583</td><td>5.94195</td></tr><tr><td>7</td><td>2.7609</td><td>2.14755</td><td>6.05918</td><td>9.08845</td><td>3.20938</td><td>6.74166</td></tr><tr><td>8</td><td>10.2185</td><td>8.50628</td><td>1.80119</td><td>3.25728</td><td>3.23209</td><td>1.75468</td></tr><tr><td>9</td><td>5.2438</td><td>5.49510</td><td>4.21994</td><td>3.70132</td><td>6.84426</td><td>4.91827</td></tr><tr><td>10</td><td>4.5590</td><td>4.04525</td><td>2.12934</td><td>5.50134</td><td>4.20694</td><td>7.26081</td></tr><tr><td>$\bar{x}$</td><td>4.401</td><td>5.928</td><td>4.229</td><td>4.132</td><td>3.620</td><td>5.761</td></tr><tr><td>$\widetilde{x}$</td><td>4.360</td><td>6.144</td><td>4.608</td><td>3.857</td><td>3.221</td><td>6.342</td></tr><tr><td>$S$</td><td>2.642</td><td>2.062</td><td>1.611</td><td>2.124</td><td>1.678</td><td>2.496</td></tr></table>

In summary, the values of the individual sample observations vary from sample to sample, so will in general the value of any quantity computed from sample data, and the value of a sample characteristic used as an estimate of the corresponding population characteristic will virtually never coincide with what is being estimated.

---

DEFINITION

---

A statistic is any quantity whose value can be calculated from sample data. Prior to obtaining data, there is uncertainty as to what value of any particular statistic will result. Therefore, a statistic is a random variable and will be denoted by an uppercase letter; a lowercase letter is used to represent the calculated or observed value of the statistic.

Thus the sample mean, regarded as a statistic (before a sample has been selected or an experiment carried out), is denoted by $\bar{X}$ ; the calculated value of this statistic is $\bar{x}$ . Similarly, $S$ represents the sample standard deviation thought of as a statistic, and its computed value is $s$ . If samples of two different types of bricks are selected and the individual compressive strengths are denoted by ${X}_{1},\ldots ,{X}_{m}$ and ${Y}_{1},\ldots ,{Y}_{n}$ , respectively, then the statistic $\bar{X} - \bar{Y}$ , the difference between the two sample mean compressive strengths, is often of great interest.

Any statistic, being a random variable, has a probability distribution. In particular, the sample mean $\bar{X}$ has a probability distribution. Suppose, for example, that $n = 2$ components are randomly selected and the number of breakdowns while under warranty is determined for each one. Possible values for the sample mean number of breakdowns $\bar{X}$ are 0 (if ${X}_{1} = {X}_{2} = 0$ ),. 5 (if either ${X}_{1} = 0$ and ${X}_{2} = 1$ or $\left. {{X}_{1} = 1\text{and}{X}_{2} = 0}\right) ,1,{1.5},\ldots$ . The probability distribution of $\bar{X}$ specifies $P\left( {\bar{X} = 0}\right)$ , $P\left( {\bar{X} = {.5}}\right)$ , and so on, from which other probabilities such as $P\left( {1 \leq \bar{X} \leq 3}\right)$ and $P\left( {\bar{X} \geq {2.5}}\right)$ can be calculated. Similarly, if for a sample of size $n = 2$ , the only possible values of the sample variance are 0,12.5, and 50 (which is the case if ${X}_{1}$ and ${X}_{2}$ can each take on only the values ${40},{45}$ , or 50 ), then the probability distribution of ${S}^{2}$ gives $P\left( {{S}^{2} = 0}\right) , P\left( {{S}^{2} = {12.5}}\right)$ , and $P\left( {{S}^{2} = {50}}\right)$ . The probability distribution of a statistic is sometimes referred to as its sampling distribution to emphasize that it describes how the statistic varies in value across all samples that might be selected.

### 5.3.1 Random Samples

The probability distribution of any particular statistic depends not only on the population distribution (normal, uniform, etc.) and the sample size $n$ but also on the method of sampling. Consider selecting a sample of size $n = 2$ from a population consisting of just the three values 1,5 , and 10 , and suppose that the statistic of interest is the sample variance. If sampling is done "with replacement," then ${S}^{2} = 0$ will result if ${X}_{1} = {X}_{2}$ . However, ${S}^{2}$ cannot equal 0 if sampling is "without replacement." So $P\left( {{S}^{2} = 0}\right) = 0$ for one sampling method, and this probability is positive for the other method. Our next definition describes a sampling method often encountered (at least approximately) in practice.

---

DEFINITION

---

The rv’s ${X}_{1},{X}_{2},\ldots ,{X}_{n}$ are said to form a (simple) random sample of size $n$ if

1. The ${X}_{i}$ ’s are independent rv’s.

2. Every ${X}_{i}$ has the same probability distribution.

Conditions 1 and 2 can be paraphrased by saying that the ${X}_{i}$ ’s are independent and identically distributed (iid). If sampling is either with replacement or from an infinite (conceptual) population, Conditions 1 and 2 are satisfied exactly. These conditions will be approximately satisfied if sampling is without replacement, yet the sample size $n$ is much smaller than the population size $N$ . In practice, if $n/N \leq {.05}$ (at most $5\%$ of the population is sampled), we can proceed as if the ${X}_{i}$ ’s form a random sample. The virtue of such random sampling is that the probability distribution of any statistic can be more easily obtained than for any other sampling procedure.

There are two general methods for obtaining information about a statistic's sampling distribution. One method involves calculations based on probability rules, and the other involves carrying out a simulation experiment.

### 5.3.2 Deriving a Sampling Distribution

Probability rules can be used to obtain the distribution of a statistic provided that it is a "fairly simple" function of the ${X}_{i}$ ’s and either there are relatively few different $X$ values in the population or else the population distribution has a "nice" form. Our next two examples illustrate such situations.

PLE 5.2.1 A certain brand of MP3 player comes in three configurations: a model with $2\mathrm{{GB}}$ of memory, costing $\$ {80}$ , a $4\mathrm{\;{GB}}$ model priced at $\$ {100}$ , and an $8\mathrm{\;{GB}}$ version with a price tag of \$120. If ${20}\%$ of all purchasers choose the 2 GB model,30% choose the 4 GB model, and ${50}\%$ choose the $8\mathrm{\;{GB}}$ model, then the probability distribution of the cost $X$ of a single randomly selected MP3 player purchase is given by

$$
\begin{array}{llll} x & {80} & {100} & {120} \\ p\left( x\right) & {.2} & {.3} & {.5} \end{array}\;\text{ with }\mu = {106},{\sigma }^{2} = {244} \tag{5.2}
$$

Suppose on a particular day only two MP3 players are sold. Let ${X}_{1} =$ the revenue from the first sale and ${X}_{2} =$ the revenue from the second. Suppose that ${X}_{1}$ and ${X}_{2}$ are independent, each with the probability distribution shown in (5.2) [so that ${X}_{1}$ and ${X}_{2}$ constitute a random sample from the distribution (5.2)]. Table 5.2 lists possible $\left( {{x}_{1},{x}_{2}}\right)$ pairs, the probability of each [computed using (5.2) and also the assumption of independence], and the resulting $\bar{x}$ and ${s}^{2}$ values. [Note that when $n = 2,{s}^{2} =$ ${\left( {x}_{1} - \bar{x}\right) }^{2} + {\left( {x}_{2} - \bar{x}\right) }^{2}$ .] Now to obtain the probability distribution of $\bar{X}$ , the sample average revenue per sale, we must consider each possible value $\bar{x}$ and compute its probability. For example, $\bar{x} = {100}$ occurs three times in the table with probabilities ${.10},{.09}$ , and .10, so

$$
{p}_{\bar{X}}\left( {100}\right) = P\left( {\bar{X} = {100}}\right) = {.10} + {.09} + {.10} = {.29}
$$

Similarly,

$$
{p}_{{S}^{2}}\left( {800}\right) = P\left( {{S}^{2} = {800}}\right) = P\left( {{X}_{1} = {80},{X}_{2} = {120}\text{ or }{X}_{1} = {120},{X}_{2} = {80}}\right)
$$

$$
= {.10} + {.10} = {.20}
$$

Table 5.2 Outcomes, Probabilities, and Values of $\bar{x}$ and ${s}^{2}$ for Example 5.21

<table><thead><tr><th>${x}_{1}$</th><th>${x}_{2}$</th><th>$p\left( {{x}_{1},{x}_{2}}\right)$</th><th>$\bar{x}$</th><th>${s}^{2}$</th></tr></thead><tr><td>80</td><td>80</td><td>.04</td><td>80</td><td>0</td></tr><tr><td>80</td><td>100</td><td>.06</td><td>90</td><td>200</td></tr><tr><td>80</td><td>120</td><td>.10</td><td>100</td><td>800</td></tr><tr><td>100</td><td>80</td><td>.06</td><td>90</td><td>200</td></tr><tr><td>100</td><td>100</td><td>.09</td><td>100</td><td>0</td></tr><tr><td>100</td><td>120</td><td>.15</td><td>110</td><td>200</td></tr><tr><td>120</td><td>80</td><td>.10</td><td>100</td><td>800</td></tr><tr><td>120</td><td>100</td><td>.15</td><td>110</td><td>200</td></tr><tr><td>120</td><td>120</td><td>.25</td><td>120</td><td>0</td></tr></table>

The complete sampling distributions of $\bar{X}$ and ${S}^{2}$ appear in (5.3) and (5.4).(5.3) (5.4)

<table><thead><tr><th>$\bar{x}$</th><th>80</th><th>90</th><th>100</th><th>110</th><th>120</th></tr></thead><tr><td>${p}_{\bar{X}}\left( \bar{x}\right)$</td><td>.04</td><td>.12</td><td>.29</td><td>.30</td><td>.25</td></tr><tr><td></td><td>0</td><td>200</td><td>800</td><td></td><td></td></tr><tr><td>${p}_{{S}^{2}}\left( {s}^{2}\right)$</td><td>.38</td><td>.42</td><td>.20</td><td></td><td></td></tr></table>

Figure 5.8 pictures a probability histogram for both the original distribution (5.2) and the $\bar{X}$ distribution (5.3). The figure suggests first that the mean (expected value) of the $\bar{X}$ distribution is equal to the mean 106 of the original distribution, since both histograms appear to be centered at the same place.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_26_526_183_1071_249_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_26_526_183_1071_249_0.jpg)

Figure 5.8 Probability histograms for the underlying distribution and $\bar{X}$ distribution in Example 5.21

From (5.3),

$$
{\mu }_{\bar{X}} = E\left( \bar{X}\right) = \sum \bar{x}{p}_{\bar{X}}\left( \bar{x}\right) = \left( {80}\right) \left( {.04}\right) + \cdots + \left( {120}\right) \left( {.25}\right) = {106} = \mu
$$

Second, it appears that the $\bar{X}$ distribution has smaller spread (variability) than the original distribution, since probability mass has moved in toward the mean. Again from (5.3),

$$
{\sigma }_{\bar{X}}^{2} = V\left( \bar{X}\right) = \sum {\bar{x}}^{2} \cdot {p}_{\bar{X}}\left( \bar{x}\right) - {\mu }_{\bar{X}}^{2}
$$

$$
= \left( {80}^{2}\right) \left( {.04}\right) + \cdots + \left( {120}^{2}\right) \left( {.25}\right) - {\left( {106}\right) }^{2}
$$

$$
= {122} = {244}/2 = {\sigma }^{2}/2
$$

The variance of $\bar{X}$ is precisely half that of the original variance (because $n = 2$ ).

Using (5.4), the mean value of ${S}^{2}$ is

$$
{\mu }_{{S}^{2}} = E\left( {S}^{2}\right) = \sum {s}^{2} \cdot {p}_{{S}^{2}}\left( {s}^{2}\right)
$$

$$
= \left( 0\right) \left( {.38}\right) + \left( {200}\right) \left( {.42}\right) + \left( {800}\right) \left( {.20}\right) = {244} = {\sigma }^{2}
$$

That is, the $\bar{X}$ sampling distribution is centered at the population mean $\mu$ , and the ${S}^{2}$ sampling distribution is centered at the population variance ${\sigma }^{2}$ .

If there had been four purchases on the day of interest, the sample average revenue $\bar{X}$ would be based on a random sample of four ${X}_{i}$ ’s, each having the distribution (5.2). Mildly tedious calculations yield the pmf of $\bar{X}$ for $n = 4$ as

<table><thead><tr><th>$\bar{x}$</th><th>80</th><th>85</th><th>90</th><th>95</th><th>100</th><th>105</th><th>110</th><th>115</th><th>120</th></tr></thead><tr><td>${p}_{\overline{X}}\left( \overline{x}\right)$</td><td>.0016</td><td>.0096</td><td>.0376</td><td>.0936</td><td>.1761</td><td>.2340</td><td>.2350</td><td>.1500</td><td>.0625</td></tr></table>

From this, ${\mu }_{\bar{X}} = {106} = \mu$ and ${\sigma }_{\bar{X}}^{2} = {61} = {\sigma }^{2}/4$ . Figure 5.9 is a probability histogram of this pmf.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_26_782_1554_599_303_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_26_782_1554_599_303_0.jpg)

Figure 5.9 Probability histogram for $\bar{X}$ based on $n = 4$ in Example 5.21

Example 5.21 should suggest first of all that the computation of ${p}_{\bar{X}}\left( \bar{x}\right)$ and ${p}_{{S}^{2}}\left( {s}^{2}\right)$ can be tedious. If the original distribution (5.2) had allowed for more than three possible values, then even for $n = 2$ the computations would have been more involved. The example should also suggest, however, that there are some general relationships between $E\left( \bar{X}\right) , V\left( \bar{X}\right) , E\left( {S}^{2}\right)$ , and the mean $\mu$ and variance ${\sigma }^{2}$ of the original distribution. These are stated in the next section. Now consider an example in which the random sample is drawn from a continuous distribution.

MPLE 5.22 Service time for a certain type of bank transaction is a random variable having an exponential distribution with parameter $\lambda$ . Suppose ${X}_{1}$ and ${X}_{2}$ are service times for two different customers, assumed independent of each other. Consider the total service time ${T}_{o} = {X}_{1} + {X}_{2}$ for the two customers, also a statistic. The cdf of ${T}_{o}$ is, for $t \geq 0$ ,

$$
{F}_{{T}_{0}}\left( t\right) = P\left( {{X}_{1} + {X}_{2} \leq t}\right) = {\iint }_{\left\{ \left( {x}_{1},{x}_{2}\right) : {x}_{1} + {x}_{2} \leq t\right\} }f\left( {{x}_{1},{x}_{2}}\right) d{x}_{1}d{x}_{2}
$$

$$
= {\int }_{0}^{t}{\int }_{0}^{t - {x}_{1}}\lambda {e}^{-\lambda {x}_{1}} \cdot \lambda {e}^{-\lambda {x}_{2}}d{x}_{2}d{x}_{1} = {\int }_{0}^{t}\left\lbrack {\lambda {e}^{-\lambda {x}_{1}} - \lambda {e}^{-{\lambda t}}}\right\rbrack d{x}_{1}
$$

$$
= 1 - {e}^{-{\lambda t}} - {\lambda t}{e}^{-{\lambda t}}
$$

The region of integration is pictured in Figure 5.10.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_27_986_720_415_281_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_27_986_720_415_281_0.jpg)

Figure 5.10 Region of integration to obtain cdf of ${T}_{o}$ in Example 5.22

The pdf of ${T}_{o}$ is obtained by differentiating ${F}_{{T}_{o}}\left( t\right)$ :

$$
{f}_{{T}_{o}}\left( t\right) = \left\{ \begin{matrix} {\lambda }^{2}t{e}^{-{\lambda t}} & t \geq 0 \\ 0 & t < 0 \end{matrix}\right. \tag{5.5}
$$

This is a gamma $\operatorname{pdf}\left( {\alpha = 2\text{and}\beta = 1/\lambda }\right)$ . The pdf of $\bar{X} = {T}_{o}/2$ is obtained from the relation $\{ \bar{X} \leq \bar{x}\}$ iff $\left\{ {{T}_{o} \leq 2\bar{x}}\right\}$ as

$$
{f}_{\bar{X}}\left( \bar{x}\right) = \left\{ \begin{matrix} 4{\lambda }^{2}\bar{x}{e}^{-{2\lambda }\bar{x}} & \bar{x} \geq 0 \\ 0 & \bar{x} < 0 \end{matrix}\right. \tag{5.6}
$$

The mean and variance of the underlying exponential distribution are $\mu = 1/\lambda$ and ${\sigma }^{2} = 1/{\lambda }^{2}$ . From Expressions (5.5) and (5.6), it can be verified that $E\left( \bar{X}\right) = 1/\lambda$ , $V\left( \bar{X}\right) = 1/\left( {2{\lambda }^{2}}\right) , E\left( {T}_{o}\right) = 2/\lambda$ , and $V\left( {T}_{o}\right) = 2/{\lambda }^{2}$ . These results again suggest some general relationships between means and variances of $\bar{X},{T}_{o}$ , and the underlying distribution.

### 5.3.3 Simulation Experiments

The second method for obtaining information about a statistic's sampling distribution is to perform a simulation experiment. This method is usually used when a derivation via probability rules is very difficult or even impossible. Such an experiment is virtually always done with the aid of a computer. The following characteristics of an experiment must be specified:

1. The statistic of interest $\left( {\bar{X}, S\text{, a particular trimmed mean, etc.}}\right)$

2. The population distribution (normal with $\mu = {100}$ and $\sigma = {15}$ , uniform with lower limit $A = 5$ and upper limit $B = {10}$ , etc.)

3. The sample size $n$ (e.g., $n = {10}$ or $n = {50}$ )

4. The number of replications $k$ (number of samples to be obtained)

Then use appropriate software to obtain $k$ different random samples, each of size $n$ , from the designated population distribution. For each sample, calculate the value of the statistic and construct a histogram of the $k$ values. This histogram gives the approximate sampling distribution of the statistic. The larger the value of $k$ , the better the approximation will tend to be (the actual sampling distribution emerges as $k \rightarrow \infty$ ). In practice, $k = {500}$ or 1000 is usually sufficient if the statistic is "fairly simple."

EXAMPLE 5.23 The population distribution for our first simulation study is normal with $\mu = {8.25}$ and $\sigma = {.75}$ , as pictured in Figure 5.11. [The article "Platelet Size in Myocardial Infarction" (British Med. J., 1983: 449-451) suggests this distribution for platelet volume in individuals with no history of serious heart problems.]

![0192609f-6f5c-74c9-8588-c1ef28b2184d_28_794_756_581_315_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_28_794_756_581_315_0.jpg)

Figure 5.11 Normal distribution, with $\mu = {8.25}$ and $\sigma = {.75}$

We actually performed four different experiments, with 500 replications for each one. In the first experiment,500 samples of $n = 5$ observations each were generated using Minitab, and the sample sizes for the other three were $n = {10}, n = {20}$ , and $n = {30}$ , respectively. The sample mean was calculated for each sample, and the resulting histograms of $\bar{x}$ values appear in Figure 5.12.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_28_507_1466_1125_666_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_28_507_1466_1125_666_0.jpg)

Figure 5.12 Sample histograms for $\bar{x}$ based on 500 samples, each consisting of $n$ observations: (a) $n = 5$ ; (b) $n = {10}$ ; (c) $n = {20}$ ; (d) $n = {30}$

Copyright 2016 Congage Learning. All Rights Reserved, May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Congage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_29_672_189_1077_631_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_29_672_189_1077_631_0.jpg)

Figure 5.12 (continued)

The first thing to notice about the histograms is their shape. To a reasonable approximation, each of the four looks like a normal curve. The resemblance would be even more striking if each histogram had been based on many more than ${500}\bar{x}$ values. Second, each histogram is centered approximately at 8.25 , the mean of the population being sampled. Had the histograms been based on an unending sequence of $\bar{x}$ values, their centers would have been exactly the population mean,8.25 .

The final aspect of the histograms to note is their spread relative to one another. The larger the value of $n$ , the more concentrated is the sampling distribution about the mean value. This is why the histograms for $n = {20}$ and $n = {30}$ are based on narrower class intervals than those for the two smaller sample sizes. For the larger sample sizes, most of the $\bar{x}$ values are quite close to 8.25 . This is the effect of averaging. When $n$ is small, a single unusual $x$ value can result in an $\bar{x}$ value far from the center. With a larger sample size, any unusual $x$ values, when averaged in with the other sample values, still tend to yield an $\bar{x}$ value close to $\mu$ . Combining these insights yields a result that should appeal to your intuition: $\bar{X}$ based on a large $n$ tends to be closer to $\mu$ than does $\bar{X}$ based on a small $n$ .

EXAMPLE 5.24 Consider a simulation experiment in which the population distribution is quite skewed. Figure 5.13 shows the density curve for lifetimes of a certain type of Copyright 2016 Cengage Learning. All Rights Reserved, May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Congage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it. electronic control [this is actually a lognormal distribution with $E\left( {\ln \left( X\right) }\right) = 3$ and $V\left( {\ln \left( X\right) }\right) = {.16}\rbrack$ . Again the statistic of interest is the sample mean $\bar{X}$ . The experiment utilized 500 replications and considered the same four sample sizes as in Example 5.23. The resulting histograms along with a normal probability plot from Minitab for the ${500}\bar{x}$ values based on $n = {30}$ are shown in Figure 5.14.

![0192609f-6f5c-74c9-8588-c1ef28b2184d_29_875_1624_686_505_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_29_875_1624_686_505_0.jpg)

Figure 5.13 Density curve for the simulation experiment of Example 5.24 [ $E\left( X\right) = {21.7584}$ , $V\left( X\right) = {82.1449}\rbrack$

![0192609f-6f5c-74c9-8588-c1ef28b2184d_30_306_438_1339_1568_0.jpg](images/0192609f-6f5c-74c9-8588-c1ef28b2184d_30_306_438_1339_1568_0.jpg)

Figure 5.14 Results of the simulation experiment of Example 5.24: (a) $\bar{x}$ histogram for $n = 5$ ; (b) $\bar{x}$ histogram for $n = {10}$ ; (c) $\bar{x}$ histogram for $n = {20}$ ; (d) $\bar{x}$ histogram for $n = {30}$ ; (e) normal probability plot for $n = {30}$ (from Minitab)

Unlike the normal case, these histograms all differ in shape. In particular, they become progressively less skewed as the sample size $n$ increases. The average of the ${500}\bar{x}$ values for the four different sample sizes are all quite close to the mean value of the population distribution. If each histogram had been based on an unending sequence of $\bar{x}$ values rather than just 500, all four would have been centered at exactly 21.7584. Thus different values of $n$ change the shape but not the center of the sampling distribution of $\bar{X}$ . Comparison of the four histograms in Figure 5.14 also shows that as $n$ increases, the spread of the histograms decreases. Increasing $n$ results in a greater degree of concentration about the population mean value and makes the histogram look more like a normal curve. The histogram of Figure 5.14(d) and the normal probability plot in Figure 5.14(e) provide convincing evidence that a sample size of $n = {30}$ is sufficient to overcome the skewness of the population distribution and give an approximately normal $\bar{X}$ sampling distribution.

### EXERCISES Section 5.3 (37-45)

37. A particular brand of dishwasher soap is sold in three sizes: ${25}\mathrm{{oz}},{40}\mathrm{{oz}}$ , and ${65}\mathrm{{oz}}$ . Twenty percent of all purchasers select a 25-oz box, 50% select a 40-oz box, and the remaining ${30}\%$ choose a 65-oz box. Let ${X}_{1}$ and ${X}_{2}$ denote the package sizes selected by two independently selected purchasers.

a. Determine the sampling distribution of $\bar{X}$ , calculate $E\left( \bar{X}\right)$ , and compare to $\mu$ .

b. Determine the sampling distribution of the sample variance ${S}^{2}$ , calculate $E\left( {S}^{2}\right)$ , and compare to ${\sigma }^{2}$ .

38. There are two traffic lights on a commuter's route to and from work. Let ${X}_{1}$ be the number of lights at which the commuter must stop on his way to work, and ${X}_{2}$ be the number of lights at which he must stop when returning from work. Suppose these two variables are independent, each with pmf given in the accompanying table (so ${X}_{1},{X}_{2}$ is a random sample of size $n = 2$ ).

$$
\begin{array}{llll} {x}_{1} & 0 & 1 & 2 \\ p\left( {x}_{1}\right) & {.2} & {.5} & {.3} \end{array}\;\mu = {1.1},{\sigma }^{2} = {.49}
$$

a. Determine the pmf of ${T}_{o} = {X}_{1} + {X}_{2}$ .

b. Calculate ${\mu }_{{T}_{o}}$ . How does it relate to $\mu$ , the population mean?

c. Calculate ${\sigma }_{{T}_{o}}^{2}$ . How does it relate to ${\sigma }^{2}$ , the population variance?

d. Let ${X}_{3}$ and ${X}_{4}$ be the number of lights at which a stop is required when driving to and from work on a second day assumed independent of the first day. With ${T}_{o} =$ the sum of all four ${X}_{i}$ ’s, what now are the values of $E\left( {T}_{o}\right)$ and $V\left( {T}_{o}\right)$ ?

e. Referring back to (d), what are the values of $P\left( {{T}_{o} = 8}\right)$ and $P\left( {{T}_{o} \geq 7}\right)$ [Hint: Don’t even think of listing all possible outcomes!]

39. It is known that ${80}\%$ of all brand A external hard drives work in a satisfactory manner throughout the warranty period (are "successes"). Suppose that $n = {15}$ drives are randomly selected. Let $X =$ the number of successes in the sample. The statistic $X/n$ is the sample proportion (fraction) of successes. Obtain the sampling distribution of this statistic. [Hint: One possible value of $X/n$ is .2, corresponding to $X = 3$ . What is the probability of this value (what kind of rv is $X)$ ?]

40. A box contains ten sealed envelopes numbered $1,\ldots ,{10}$ . The first five contain no money, the next three each contains $\$ 5$ , and there is a $\$ {10}$ bill in each of the last two. A sample of size 3 is selected with replacement (so we have a random sample), and you get the largest amount in any of the envelopes selected. If ${X}_{1},{X}_{2}$ , and ${X}_{3}$ denote the amounts in the selected envelopes, the statistic of interest is $M =$ the maximum of ${X}_{1},{X}_{2}$ , and ${X}_{3}$ .

a. Obtain the probability distribution of this statistic.

b. Describe how you would carry out a simulation experiment to compare the distributions of $M$ for various sample sizes. How would you guess the distribution would change as $n$ increases?

41. Let $X$ be the number of packages being mailed by a randomly selected customer at a certain shipping facility. Suppose the distribution of $X$ is as follows:

<table><tr><td>$x$</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>$p\left( x\right)$</td><td>.4</td><td>.3</td><td>.2</td><td>.1</td></tr></table>

a. Consider a random sample of size $n = 2$ (two customers), and let $\bar{X}$ be the sample mean number of packages shipped. Obtain the probability distribution of $\bar{X}$ .

b. Refer to part (a) and calculate $P\left( {\bar{X} \leq {2.5}}\right)$ .

c. Again consider a random sample of size $n = 2$ , but now focus on the statistic $R =$ the sample range (difference between the largest and smallest values in the sample). Obtain the distribution of $R$ . [Hint: Calculate the value of $R$ for each outcome and use the probabilities from part (a).]

d. If a random sample of size $n = 4$ is selected, what is $P\left( {\bar{X} \leq {1.5}}\right)$ ? [Hint: You should not have to list all possible outcomes, only those for which $\bar{x} \leq {1.5}$ .]

42. A company maintains three offices in a certain region, each staffed by two employees. Information concerning yearly salaries (1000s of dollars) is as follows:

<table><tr><td>Office</td><td>1</td><td>1</td><td>2</td><td>2</td><td>3</td><td>3</td></tr><tr><td>Employee</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>Salary</td><td>29.7</td><td>33.6</td><td>30.2</td><td>33.6</td><td>25.8</td><td>29.7</td></tr></table>

a. Suppose two of these employees are randomly selected from among the six (without replacement). Determine the sampling distribution of the sample mean salary $\bar{X}$ .

b. Suppose one of the three offices is randomly selected. Let ${X}_{1}$ and ${X}_{2}$ denote the salaries of the two employees. Determine the sampling distribution of $\bar{X}$ .

c. How does $E\left( \bar{X}\right)$ from parts (a) and (b) compare to the population mean salary $\mu$ ?

43. Suppose the amount of liquid dispensed by a certain machine is uniformly distributed with lower limit $A = 8\mathrm{{oz}}$ and upper limit $B = {10}$ oz. Describe how you would carry out simulation experiments to compare the sampling distribution of the (sample) fourth spread for sample sizes $n = 5,{10},{20}$ , and 30 .

44. Carry out a simulation experiment using a statistical computer package or other software to study the sampling distribution of $\bar{X}$ when the population distribution is Weibull with $\alpha = 2$ and $\beta = 5$ , as in Example 5.20. Consider the four sample sizes $n = 5,{10},{20}$ , and 30, and in each case use 1000 replications. For which of these sample sizes does the $\bar{X}$ sampling distribution appear to be approximately normal?

45. Carry out a simulation experiment using a statistical computer package or other software to study the sampling distribution of $\bar{X}$ when the population distribution is lognormal with $E\left( {\ln \left( X\right) }\right) = 3$ and $V\left( {\ln \left( X\right) }\right) = 1$ . Consider the four sample sizes $n = {10},{20},{30}$ , and 50, and in each case use 1000 replications. For which of these sample sizes does the $\bar{X}$ sampling distribution appear to be approximately normal?