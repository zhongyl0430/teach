When $X \sim N\left( {\mu ,{\sigma }^{2}}\right)$ , probabilities involving $X$ are computed by "standardizing." The standardized variable is $\left( {X - \mu }\right) /\sigma$ . Subtracting $\mu$ shifts the mean from $\mu$ to zero, and then dividing by $\sigma$ scales the variable so that the standard deviation is 1 rather than $\sigma$ .

> [!proposition]
> If $X$ has a normal distribution with mean $\mu$ and standard deviation $\sigma$ , then
> 
> $$
> Z = \frac{X - \mu }{\sigma }
> $$
> 
> has a standard normal distribution. Thus
> 
> $$
> \begin{align}
> &P(a \leq X \leq b) \\
> &= P\left( \frac{a - \mu}{\sigma} \leq Z \leq \frac{b - \mu}{\sigma} \right) \\
> &= \Phi\left( \frac{b - \mu}{\sigma} \right) - \Phi\left( \frac{a - \mu}{\sigma} \right).
> \end{align}
> $$
> 
> $$
> P\left( {X \leq a}\right) = \Phi \left( \frac{a - \mu }{\sigma }\right)
> $$
> $$P\left( {X \geq b}\right) = 1 - \Phi \left( \frac{b - \mu }{\sigma }\right)
> $$

According to the first part of the proposition, the area under the normal $\left( {\mu ,{\sigma }^{2}}\right)$ curve that lies above the interval $\left\lbrack {a, b}\right\rbrack$ is identical to the area under the standard normal curve that lies above the interval from the standardized lower limit $\left( {a - \mu }\right) /\sigma$ to the standardized upper limit $\left( {b - \mu }\right) /\sigma$ . An illustration of the second part appears in Figure 4.21. 

Figure 4.21 
Equality of nonstandard and standard normal curve areas
![01925166-48c0-7eca-9860-67f13d0848b1_21_704_189_752_265_0.jpg](images/01925166-48c0-7eca-9860-67f13d0848b1_21_704_189_752_265_0.jpg)

The key idea is that by standardizing, any probability involving $X$ can be expressed as a probability involving a standard normal rv $Z$ , so that Appendix Table A. 3 can be used. The proposition can be proved by writing the cdf of $Z = \left( {X - \mu }\right) /\sigma$ as

$$
\begin{align}
P(Z \leq z) &= P\left( X \leq \sigma z + \mu \right) \\
&= \int_{-\infty}^{\sigma z + \mu} f(x; \mu, \sigma) \, dx.
\end{align}
$$


Using a result from calculus, this integral can be differentiated with respect to $z$ to yield the desired $\operatorname{pdf}f\left( {z;0,1}\right)$ .

[[EX 4.16]]

Standardizing amounts to nothing more than calculating a distance from the mean value and then reexpressing the distance as some number of standard deviations. 
Thus, if $\mu = {100}$ and $\sigma = {15}$ , then $x = {130}$ corresponds to $z = \left( {{130} - {100}}\right) /{15} =$ ${30}/{15} = {2.00}$ . 
That is,130 is 2 standard deviations above (to the right of) the mean value. 
Similarly, standardizing ${85}$ gives $\left( {{85} - {100}}\right) /{15} = - {1.00}$ , so 85 is 1 standard deviation below the mean. 
The $z$ table applies to any normal distribution provided that we think in terms of number of standard deviations away from the mean value.

[[EX 4.17]]

The results of Example 4.17 are often reported in percentage form and referred to as the empirical rule (because empirical evidence has shown that histograms of real data can very frequently be approximated by normal curves).

> [!remark]
> If the population distribution of a variable is (approximately) normal, then
> 1. Roughly ${68}\%$ of the values are within $1\mathrm{{SD}}$ of the mean.
> 2. Roughly ${95}\%$ of the values are within $2\mathrm{{SDs}}$ of the mean.
> 3. Roughly ${99.7}\%$ of the values are within $3\mathrm{{SDs}}$ of the mean.

It is indeed unusual to observe a value from a normal population that is much farther than 2 standard deviations from $\mu$. 
These results will be important in the development of hypothesis-testing procedures in later chapters.