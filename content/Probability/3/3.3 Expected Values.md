# 3.3 Expected Values

Consider a university having 15,000 students and let $X =$ the number of
courses for which a randomly selected student is registered. The pmf of
$X$ follows. Since $p\left( 1\right) = {.01}$ , we know that
$\left( {.01}\right) \cdot \left( {{15},{000}}\right) = {150}$ of the
students are registered for one course, and similarly for the other $x$
values.

::: center
:::

(3.6)

The average number of courses per student, or the average value of $X$
in the population, results from computing the total number of courses
taken by all students and dividing by the total number of students.
Since each of 150 students is taking one course, these 150 contribute
150 courses to the total. Similarly, 450 students contribute 2(450)
courses, and so on. The population average value of $X$ is then

$$\frac{1\left( {150}\right) + 2\left( {450}\right) + 3\left( {1950}\right) + \cdots + 7\left( {300}\right) }{{15},{000}} = {4.57} \tag{3.7}$$

Since
${150}/{15},{000} = {.01} = p\left( 1\right) ,{450}/{15},{000} = {.03} = p\left( 2\right)$
, and so on, an alternative expression for (3.7) is

$$1 \cdot p\left( 1\right) + 2 \cdot p\left( 2\right) + \cdots + 7 \cdot p\left( 7\right) \tag{3.8}$$

Expression (3.8) shows that to compute the population average value of
$X$ , we need only the possible values of $X$ along with their
probabilities (proportions). In particular, the population size is
irrelevant as long as the pmf is given by (3.6). The average or mean
value of $X$ is then a weighted average of the possible values
$1,\ldots ,7$ , where the weights are the probabilities of those values.

## The Expected Value of $X$

Let $X$ be a discrete rv with set of possible values $D$ and
$\operatorname{pmf}p\left( x\right)$ . The expected value or mean value
of $X$ , denoted by $E\left( X\right)$ or ${\mu }_{X}$ or just $\mu$ ,
is

$$E\left( X\right) = {\mu }_{X} = \mathop{\sum }\limits_{{x \in D}}x \cdot p\left( x\right)$$

EXAMPLE 3.16 For the pmf of $X =$ number of courses in (3.6),

$$\mu = 1 \cdot p\left( 1\right) + 2 \cdot p\left( 2\right) + \cdots + 7 \cdot p\left( 7\right)$$

$$= \left( 1\right) \left( {.01}\right) + 2\left( {.03}\right) + \cdots + \left( 7\right) \left( {.02}\right)$$

$$= {.01} + {.06} + {.39} + {1.00} + {1.95} + {1.02} + {.14} = {4.57}$$

If we think of the population as consisting of the $X$ values
$1,2,\ldots ,7$ , then $\mu = {4.57}$ is the population mean. In the
sequel, we will often refer to $\mu$ as the population mean rather than
the mean of $X$ in the population. Notice that $\mu$ here is not 4, the
ordinary average of $1,\ldots ,7$ , because the distribution puts more
weight on 4,5, and 6 than on other $X$ values.

In Example 3.16, the expected value $\mu$ was 4.57, which is not a
possible value of $X$ . The word expected should be interpreted with
caution because one would not expect to see an $X$ value of 4.57 when a
single student is selected.

EXAMPLE 3.17 Just after birth, each newborn child is rated on a scale
called the Apgar scale. The possible ratings are $0,1,\ldots ,{10}$ ,
with the child's rating determined by color, muscle tone, respiratory
effort, heartbeat, and reflex irritability (the best possible score is
10). Let $X$ be the Apgar score of a randomly selected child born at a
certain hospital during the next year, and suppose that the pmf of $X$
is

::: center
:::

Then the mean value of $X$ is

$$E\left( X\right) = \mu = 0\left( {.002}\right) + 1\left( {.001}\right) + 2\left( {.002}\right)$$

$$+ \cdots + 8\left( {.25}\right) + 9\left( {.12}\right) + {10}\left( {.01}\right)$$

$$= {7.15}$$

Again, $\mu$ is not a possible value of the variable $X$ . Also, because
the variable relates to a future child, there is no concrete existing
population to which $\mu$ refers. Instead, we think of the pmf as a
model for a conceptual population consisting of the values
$0,1,2,\ldots ,{10}$ . The mean value of this conceptual population is
then $\mu = {7.15}$ .

EXAMPLE 3.18 Let $X = 1$ if a randomly selected vehicle passes an
emissions test and $X = 0$ otherwise. Then $X$ is a Bernoulli rv with
$\operatorname{pmf}p\left( 1\right) = p$ and $p\left( 0\right) = 1 - p$
, from which
$E\left( X\right) = 0 \cdot p\left( 0\right) + 1 \cdot p\left( 1\right) = 0\left( {1 - p}\right) + 1\left( p\right) = p$
. That is, the expected value of $X$ is just the probability that $X$
takes on the value 1 . If we conceptualize a population consisting of
$0\mathrm{\;s}$ in proportion $1 - p$ and $1\mathrm{\;s}$ in proportion
$p$ , then the population average is $\mu = p$ .

EXAMPLE 3.19 The general form for the pmf of $X =$ the number of
children born up to and including the first boy is

$$p\left( x\right) = \left\{ \begin{matrix} p{\left( 1 - p\right) }^{x - 1} & x = 1,2,3,\ldots \\ 0 & \text{ otherwise } \end{matrix}\right.$$

From the definition,

$$E\left( X\right) = \mathop{\sum }\limits_{D}x \cdot p\left( x\right) = \mathop{\sum }\limits_{{x = 1}}^{\infty }{xp}{\left( 1 - p\right) }^{x - 1} = p\mathop{\sum }\limits_{{x = 1}}^{\infty }\left\lbrack {-\frac{d}{dp}{\left( 1 - p\right) }^{x}}\right\rbrack \tag{3.9}$$

Interchanging the order of taking the derivative and the summation, the
sum is that of a geometric series. After the sum is computed, the
derivative is taken, resulting in $E\left( X\right) = 1/p$ . If $p$ is
near 1, we expect to see a boy very soon, whereas if $p$ is near 0, we
expect many births before the first boy. For
$p = {.5},E\left( X\right) = 2$ .

There is another frequently used interpretation of $\mu$ . Consider
observing a first value ${x}_{1}$ of $X$ , then a second value ${x}_{2}$
, a third value ${x}_{3}$ , and so on. After doing this a large number
of times, calculate the sample average of the observed
${x}_{\mathrm{i}}^{\prime }\mathrm{s}$ . This average will typically be
quite close to $\mu$ . That is, $\mu$ can be interpreted as the longrun
average observed value of $X$ when the experiment is performed
repeatedly. In Example 3.17, the long-run average Apgar score is
$\mu = {7.15}$ .

EXAMPLE 3.20 Let $X$ , the number of interviews a student has prior to
getting a job, have pmf

$$p\left( x\right) = \left\{ \begin{array}{ll} k/{x}^{2} & x = 1,2,3,\ldots \\ 0 & \text{ otherwise } \end{array}\right.$$

where $k = {\pi }^{2}/6$ insures that ${\sum p}\left( x\right) = 1$ (the
value of $k$ comes from a result in Fourier series). The expected value
of $X$ is

$$\mu = E\left( X\right) = \mathop{\sum }\limits_{{x = 1}}^{\infty }x \cdot \frac{k}{{x}^{2}} = k\mathop{\sum }\limits_{{x = 1}}^{\infty }\frac{1}{x} \tag{3.10}$$

The sum on the right of Equation (3.10) is the famous harmonic series of
mathematics and can be shown to equal $\infty .E\left( X\right)$ is not
finite here because $p\left( x\right)$ does not decrease sufficiently
fast as $x$ increases; statisticians say that the probability
distribution of $X$ has \"a heavy tail.\" If a sequence of $X$ values is
chosen using this distribution, the sample average will not settle down
to some finite number but will tend to grow without bound.

Statisticians use the phrase \"heavy tails\" in connection with any
distribution having a large amount of probability far from $\mu$ (so
heavy tails do not require $\mu = \infty$ ). Such heavy tails make it
difficult to make inferences about $\mu$ .

## The Expected Value of a Function 

Sometimes interest will focus on the expected value of some function
$h\left( X\right)$ rather than on just $E\left( X\right)$ .

EXAMPLE 3.21 Suppose a bookstore purchases ten copies of a book at
\$6.00 each to sell at \$12.00 with the understanding that at the end of
a 3-month period any unsold copies can be redeemed for $\$ {2.00}$ . If
$X =$ the number of copies sold, then net revenue $= h\left( X\right) =$
${12X} + 2\left( {{10} - X}\right) - {60} = {10X} - {40}$ . In this
situation, we might be interested not only in the expected number of
copies sold \[i.e., $E\left( X\right)$ \] but also in the expected net
revenue-that is, the expected value of a particular function of $X$ .

An easy way of computing the expected value of $h\left( X\right)$ is
suggested by the following example.

EXAMPLE 3.22 The cost of a certain vehicle diagnostic test depends on
the number of cylinders $X$ in the vehicle's engine. Suppose the cost
function is given by $h\left( X\right) = {20} + {3X} + {.5}{X}^{2}$ .
Since $X$ is a random variable, so is $Y = h\left( X\right)$ . The pmf
of $X$ and derived pmf of $Y$ are as follows:

$$\begin{array}{llll} x & 4 & 6 & 8 \\ p\left( x\right) & {.5} & {.3} & {.2} \end{array} \Rightarrow \frac{y}{p\left( y\right) }\;\begin{array}{lll} {40} & {56} & {76} \\ {.5} & {.3} & {.2} \end{array}$$

With ${D}^{ * }$ denoting possible values of $Y$ ,

$$E\left( Y\right) = E\left\lbrack {h\left( X\right) }\right\rbrack = \mathop{\sum }\limits_{{D}^{ * }}y \cdot p\left( y\right)$$

$$= \left( {40}\right) \left( {.5}\right) + \left( {56}\right) \left( {.3}\right) + \left( {76}\right) \left( {.2}\right) \tag{3.11}$$

$$= h\left( 4\right) \cdot \left( {.5}\right) + h\left( 6\right) \cdot \left( {.3}\right) + h\left( 8\right) \cdot \left( {.2}\right)$$

$$= \mathop{\sum }\limits_{D}h\left( x\right) \cdot p\left( x\right)$$

According to Equation (3.11), it was not necessary to determine the pmf
of $Y$ to obtain $E\left( Y\right)$ ; instead, the desired expected
value is a weighted average of the possible $h\left( x\right)$ (rather
than $x$ ) values.

PROPOSITION If the $\operatorname{rv}X$ has a set of possible values $D$
and $\operatorname{pmf}p\left( x\right)$ , then the expected value of
any function $h\left( X\right)$ , denoted by
$E\left\lbrack {h\left( X\right) }\right\rbrack$ or
${\mu }_{h\left( X\right) }$ , is computed by

$$E\left\lbrack {h\left( X\right) }\right\rbrack = \mathop{\sum }\limits_{D}h\left( x\right) \cdot p\left( x\right)$$

That is, $E\left\lbrack {h\left( X\right) }\right\rbrack$ is computed in
the same way that $E\left( X\right)$ itself is, except that
$h\left( x\right)$ is substituted in place of $x$ .

EXAMPLE 3.23 A computer store has purchased three computers of a certain
type at $\$ {500}$ apiece. It will sell them for $\$ {1000}$ apiece. The
manufacturer has agreed to repurchase any computers still unsold after a
specified period at $\$ {200}$ apiece. Let $X$ denote the number of
computers sold, and suppose that
$p\left( 0\right) = {.1},p\left( 1\right) = {.2}$ ,
$p\left( 2\right) = {.3}$ , and $p\left( 3\right) = {.4}$ . With
$h\left( X\right)$ denoting the profit associated with

selling $X$ units, the given information implies that
$h\left( X\right) =$ revenue $- \operatorname{cost} =$
${1000X} + {200}\left( {3 - X}\right) - {1500} = {800X} - {900}$ . The
expected profit is then

$$E\left\lbrack {h\left( X\right) }\right\rbrack = h\left( 0\right) \cdot p\left( 0\right) + h\left( 1\right) \cdot p\left( 1\right) + h\left( 2\right) \cdot p\left( 2\right) + h\left( 3\right) \cdot p\left( 3\right)$$

$$= \left( {-{900}}\right) \left( {.1}\right) + \left( {-{100}}\right) \left( {.2}\right) + \left( {700}\right) \left( {.3}\right) + \left( {1500}\right) \left( {.4}\right)$$

$$= \$ {700}$$

## Expected Value of a Linear Function 

The $h\left( X\right)$ function of interest is quite frequently a linear
function ${aX} + b$ . In this case,
$E\left\lbrack {h\left( X\right) }\right\rbrack$ is easily computed from
$E\left( X\right)$ without the need for additional summation.

$$E\left( {{aX} + b}\right) = a \cdot E\left( X\right) + b$$

::: mdframed
PROPOSITION
:::

(Or, using alternative notation,
${\mu }_{{aX} + b} = a \cdot {\mu }_{X} + b$ )

To paraphrase, the expected value of a linear function equals the linear
function evaluated at the expected value $E\left( X\right)$ . Since
$h\left( X\right)$ in Example 3.23 is linear and
$E\left( X\right) = 2,E\left\lbrack {h\left( X\right) }\right\rbrack = {800}\left( 2\right) - {900} = \$ {700}$
, as before.

Proof

$$E\left( {{aX} + b}\right) = \mathop{\sum }\limits_{D}\left( {{ax} + b}\right) \cdot p\left( x\right) = a\mathop{\sum }\limits_{D}x \cdot p\left( x\right) + b\mathop{\sum }\limits_{D}p\left( x\right)$$

$$= {aE}\left( X\right) + b$$

Two special cases of the proposition yield two important rules of
expected value.

1\. For any constant $a,E\left( {aX}\right) = a \cdot E\left( X\right)$
(take $b = 0$ ).(3.12)

2\. For any constant $b,E\left( {X + b}\right) = E\left( X\right) + b$
(take $a = 1$ ).

Multiplication of $X$ by a constant $a$ typically changes the unit of
measurement, for example, from inches to $\mathrm{{cm}}$ , where
$a = {2.54}$ . Rule 1 says that the expected value in the new units
equals the expected value in the old units multiplied by the conversion
factor $a$ . Similarly, if a constant $b$ is added to each possible
value of $X$ , then the expected value will be shifted by that same
constant amount.

## The Variance of $X$

The expected value of $X$ describes where the probability distribution
is centered. Using the physical analogy of placing point mass
$p\left( x\right)$ at the value $x$ on a one-dimensional axis, if the
axis were then supported by a fulcrum placed at $\mu$ , there would be
no tendency for the axis to tilt. This is illustrated for two different
distributions in Figure 3.7. Copyright 2016 Congage Learning. All Rights
Reserved. May not be copied, scanned, or duplicated, in whole or in
part. Due to electronic rights, some third party content may be
suppressed from the eBook and/or eChapter(s). Editorial review has
deemed that any suppressed content does not materially affect the
overall learning experience. Congage Learning reserves the right to
remove additional content at any time if subsequent rights restrictions
require it.

::: center
![image](images/019165cb-e657-75f5-b964-f15ddb80567f_19_883618.jpg){width="80%"}
:::

Figure 3.7 Two different probability distributions with $\mu = 4$

Although both distributions pictured in Figure 3.7 have the same center
$\mu$ , the distribution of Figure 3.7(b) has greater spread (i.e.,
variability or dispersion) than does that of Figure 3.7(a). We will use
the variance of $X$ to assess the amount of variability in (the
distribution of) $X$ , just as ${s}^{2}$ was used in Chapter 1 to
measure variability in a sample.

::: mdframed
DEFINITION
:::

Let $X$ have $\operatorname{pmf}p\left( x\right)$ and expected value
$\mu$ . Then the variance of $X$ , denoted by $V\left( X\right)$ or
${\sigma }_{X}^{2}$ , or just ${\sigma }^{2}$ , is

$$V\left( X\right) = \mathop{\sum }\limits_{D}{\left( x - \mu \right) }^{2} \cdot p\left( x\right) = E\left\lbrack {\left( X - \mu \right) }^{2}\right\rbrack$$

The standard deviation (SD) of $X$ is

$${\sigma }_{X} = \sqrt{{\sigma }_{X}^{2}}$$

The quantity $h\left( X\right) = {\left( X - \mu \right) }^{2}$ is the
squared deviation of $X$ from its mean, and ${\sigma }^{2}$ is the
expected squared deviation-i.e., the weighted average of squared
deviations, where the weights are probabilities from the distribution.
If most of the probability distribution is close to $\mu$ , then
${\sigma }^{2}$ will be relatively small. However, if there are $x$
values far from $\mu$ that have large $p\left( x\right)$ , then
${\sigma }^{2}$ will be quite large. Very roughly, $\sigma$ can be
interpreted as the size of a representative deviation from the mean
value $\mu$ . So if $\sigma = {10}$ , then in a long sequence of
observed $X$ values, some will deviate from $\mu$ by more than 10 while
others will be closer to the mean than that-a typical deviation from the
mean will be something on the order of 10 .

EXAMPLE 3.24 A library has an upper limit of 6 on the number of DVDs
that can be checked out to an individual at one time. Consider only
those who currently have DVDs checked out, and let $X$ denote the number
of DVDs checked out to a randomly selected individual. The pmf of $X$ is
as follows:

::: center
:::

The expected value of $X$ is easily seen to be $\mu = {2.85}$ . The
variance of $X$ is then

$$V\left( X\right) = {\sigma }^{2} = \mathop{\sum }\limits_{{x = 1}}^{6}{\left( x - {2.85}\right) }^{2} \cdot p\left( x\right)$$

$$= {\left( 1 - {2.85}\right) }^{2}\left( {.30}\right) + {\left( 2 - {2.85}\right) }^{2}\left( {.25}\right) + \cdots + {\left( 6 - {2.85}\right) }^{2}\left( {.15}\right) = {3.2275}$$

The standard deviation of $X$ is $\sigma = \sqrt{3.2275} = {1.800}$ .

When the pmf $p\left( x\right)$ specifies a mathematical model for the
distribution of population values, both ${\sigma }^{2}$ and $\sigma$
measure the spread of values in the population; ${\sigma }^{2}$ is the
population variance, and $\sigma$ is the population standard deviation.

## A Shortcut Formula for ${\mathbf{\sigma }}^{2}$

The number of arithmetic operations necessary to compute ${\sigma }^{2}$
can be reduced by using an alternative formula.

PROPOSITION

$$V\left( X\right) = {\sigma }^{2} = \left\lbrack {\mathop{\sum }\limits_{D}{x}^{2} \cdot p\left( x\right) }\right\rbrack - {\mu }^{2} = E\left( {X}^{2}\right) - {\left\lbrack E\left( X\right) \right\rbrack }^{2}$$

In using this formula, $E\left( {X}^{2}\right)$ is computed first
without any subtraction; then $E\left( X\right)$ is computed, squared,
and subtracted (once) from $E\left( {X}^{2}\right)$ .

::: mdframed
EXAMPLE 3.25

(Example 3.24 continued)
:::

The pmf of the number $X$ of DVDs checked out was given as
$p\left( 1\right) = {.30},p\left( 2\right) = {.25}$ ,
$p\left( 3\right) = {.15},p\left( 4\right) = {.05},p\left( 5\right) = {.10}$
, and $p\left( 6\right) = {.15}$ , from which $\mu = {2.85}$ and

$$E\left( {X}^{2}\right) = \mathop{\sum }\limits_{{x = 1}}^{6}{x}^{2} \cdot p\left( x\right) = \left( {1}^{2}\right) \left( {.30}\right) + \left( {2}^{2}\right) \left( {.25}\right) + \cdots + \left( {6}^{2}\right) \left( {.15}\right) = {11.35}$$

Thus ${\sigma }^{2} = {11.35} - {\left( {2.85}\right) }^{2} = {3.2275}$
as obtained previously from the definition.

Proof of the Shortcut Formula Expand ${\left( x - \mu \right) }^{2}$ in
the definition of ${\sigma }^{2}$ to obtain
${x}^{2} - {2\mu x} + {\mu }^{2}$ , and then carry $\sum$ through to
each of the three terms:

$${\sigma }^{2} = \mathop{\sum }\limits_{D}{x}^{2} \cdot p\left( x\right) - {2\mu } \cdot \mathop{\sum }\limits_{D}x \cdot p\left( x\right) + {\mu }^{2}\mathop{\sum }\limits_{D}p\left( x\right)$$

$$= E\left( {X}^{2}\right) - {2\mu } \cdot \mu + {\mu }^{2} = E\left( {X}^{2}\right) - {\mu }^{2}$$

## Variance of a Linear Function

The variance of $h\left( X\right)$ is the expected value of the squared
difference between $h\left( X\right)$ and its expected value:

$$V\left\lbrack {h\left( X\right) }\right\rbrack = {\sigma }_{h\left( X\right) }^{2} = \mathop{\sum }\limits_{D}\{ h\left( x\right) - E\left\lbrack {h\left( X\right) }\right\rbrack {\} }^{2} \cdot p\left( x\right) \tag{3.13}$$

When $h\left( X\right) = {aX} + b$ , a linear function,

$$h\left( x\right) - E\left\lbrack {h\left( X\right) }\right\rbrack = {ax} + b - \left( {{a\mu } + b}\right) = a\left( {x - \mu }\right)$$

Substituting this into (3.13) gives a simple relationship between
$V\left\lbrack {h\left( X\right) }\right\rbrack$ and $V\left( X\right)$
:

PROPOSITION

$$V\left( {{aX} + b}\right) = {\sigma }_{{aX} + b}^{2} = {a}^{2} \cdot {\sigma }_{X}^{2}\;\text{ and }\;{\sigma }_{{aX} + b} = \left| a\right| \cdot {\sigma }_{X}$$

In particular,

$${\sigma }_{aX} = \left| a\right| \cdot {\sigma }_{X},\;{\sigma }_{X + b} = {\sigma }_{X} \tag{3.14}$$

The absolute value is necessary because $a$ might be negative, yet a
standard deviation cannot be. Usually multiplication by $a$ corresponds
to a change in the unit of measurement (e.g., $\mathrm{{kg}}$ to
$\mathrm{{lb}}$ or dollars to euros). According to the first relation in
(3.14), the sd in the new unit is the original sd multiplied by the
conversion factor. The second relation says that adding or subtracting a
constant does not impact variability; it just rigidly shifts the
distribution to the right or left.

EXAMPLE 3.26 In the computer sales scenario of Example 3.23,
$E\left( X\right) = 2$ and

$$E\left( {X}^{2}\right) = {\left( 0\right) }^{2}\left( {.1}\right) + {\left( 1\right) }^{2}\left( {.2}\right) + {\left( 2\right) }^{2}\left( {.3}\right) + {\left( 3\right) }^{2}\left( {.4}\right) = 5$$

so $V\left( X\right) = 5 - {\left( 2\right) }^{2} = 1$ . The profit
function $h\left( X\right) = {800X} - {900}$ then has variance
${\left( {800}\right) }^{2} \cdot V\left( X\right) = \left( {{640},{000}}\right) \left( 1\right) = {640},{000}$
and standard deviation 800 .

## EXERCISES Section 3.3 (29-45) 

29\. The pmf of the amount of memory $X\left( \mathrm{{GB}}\right)$ in a
purchased flash drive was given in Example 3.13 as

::: center
:::

Compute the following:

a\. $E\left( X\right)$

b\. $V\left( X\right)$ directly from the definition

c\. The standard deviation of $X$

d\. $V\left( X\right)$ using the shortcut formula

30\. An individual who has automobile insurance from a certain company
is randomly selected. Let $Y$ be the number of moving violations for
which the individual was cited during the last 3 years. The pmf of $Y$
is

::: center
:::

a\. Compute $E\left( Y\right)$ .

b\. Suppose an individual with $Y$ violations incurs a surcharge of
$\$ {100}{Y}^{2}$ . Calculate the expected amount of the surcharge.

31\. Refer to Exercise 12 and calculate $V\left( Y\right)$ and
${\sigma }_{Y}$ . Then determine the probability that $Y$ is within 1
standard deviation of its mean value.

32\. A certain brand of upright freezer is available in three different
rated capacities: ${16}{\mathrm{{ft}}}^{3},{18}{\mathrm{{ft}}}^{3}$ ,
and ${20}{\mathrm{{ft}}}^{3}$ . Let $X =$ the rated capacity of a
freezer of this brand sold at a certain store. Suppose that $X$ has pmf

::: center
:::

a\. Compute $E\left( X\right) ,E\left( {X}^{2}\right)$ , and
$V\left( X\right)$ .

b\. If the price of a freezer having capacity $X$ is ${70X} - {650}$ ,
what is the expected price paid by the next customer to buy a freezer?

c\. What is the variance of the price paid by the next customer?

d\. Suppose that although the rated capacity of a freezer is $X$ , the
actual capacity is $h\left( X\right) = X - {.008}{X}^{2}$ . What is the
expected actual capacity of the freezer purchased by the next customer?

33\. Let $X$ be a Bernoulli rv with pmf as in Example 3.18.

a\. Compute $E\left( {X}^{2}\right)$ .

b\. Show that $V\left( X\right) = p\left( {1 - p}\right)$ .

c\. Compute $E\left( {X}^{79}\right)$ .

34\. Suppose that the number of plants of a particular type found in a
rectangular sampling region (called a quadrat by ecologists) in a
certain geographic area is an rv $X$ with pmf

$$p\left( x\right) = \left\{ \begin{array}{ll} \mathrm{c}/{x}^{3} & x = 1,2,3,\ldots \\ 0 & \text{ otherwise } \end{array}\right.$$

Is $E\left( X\right)$ finite? Justify your answer (this is another
distribution that statisticians would call heavy-tailed).

35\. A small market orders copies of a certain magazine for its magazine
rack each week. Let $X =$ demand for the magazine, with pmf

::: center
:::

Suppose the store owner actually pays $\$ {2.00}$ for each copy of the
magazine and the price to customers is $\$ {4.00}$ . If magazines left
at the end of the week have no salvage value, is it better to order
three or four copies of the magazine? \[Hint: For both three and four
copies ordered, express net revenue as a function of demand $X$ , and
then compute the expected revenue.\]

36\. Let $X$ be the damage incurred (in $\$$ ) in a certain type of
accident during a given year. Possible $X$ values are 0, ${1000},{5000}$
, and 10000, with probabilities .8,.1,.08, and .02 , respectively. A
particular company offers a \$500 deductible policy. If the company
wishes its expected profit to be $\$ {100}$ , what premium amount should
it charge?

37\. The $n$ candidates for a job have been ranked $1,2,3,\ldots ,n$ .
Let $X =$ the rank of a randomly selected candidate, so that $X$ has pmf

$$p\left( x\right) = \left\{ \begin{array}{ll} 1/n & x = 1,2,3,\ldots ,n \\ 0 & \text{ otherwise } \end{array}\right.$$

(this is called the discrete uniform distribution). Compute
$E\left( X\right)$ and $V\left( X\right)$ using the shortcut formula.
\[Hint: The sum of the first $n$ positive integers is
$n\left( {n + 1}\right) /2$ , whereas the sum of their squares is
$n\left( {n + 1}\right) \left( {{2n} + 1}\right) /6$ .\]

38\. Possible values of $X$ , the number of components in a system
submitted for repair that must be replaced, are 1 , 2,3, and 4 with
corresponding probabilities ${.15},{.35},{.35}$ , and .15 ,
respectively.

a\. Calculate $E\left( X\right)$ and then $E\left( {5 - X}\right)$ .

b\. Would the repair facility be better off charging a flat fee of
$\$ {75}$ or else the amount
$\$ \left\lbrack {{150}/\left( {5 - X}\right) }\right\rbrack$ ? \[Note:
It is not generally true that
$E\left( {c/Y}\right) = c/E\left( Y\right)$ .\]

39\. A chemical supply company currently has in stock
${100}\mathrm{{lb}}$ of a certain chemical, which it sells to customers
in 5-lb batches. Let $X =$ the number of batches ordered by a randomly
chosen customer, and suppose that $X$ has pmf

::: center
:::

Compute $E\left( X\right)$ and $V\left( X\right)$ . Then compute the
expected number of pounds left after the next customer's order is
shipped and the variance of the number of pounds left. \[Hint: The
number of pounds left is a linear function of $X$ .\]

40\. a. Draw a line graph of the pmf of $X$ in Exercise 35. Then
determine the pmf of $- X$ and draw its line graph. From these two
pictures, what can you say about $V\left( X\right)$ and
$V\left( {-X}\right)$ ?

b\. Use the proposition involving $V\left( {{aX} + b}\right)$ to
establish a general relationship between $V\left( X\right)$ and
$V\left( {-X}\right)$ .

41\. Use the definition in Expression (3.13) to prove that
$V\left( {{aX} + b}\right) = {a}^{2} \cdot {\sigma }_{X}^{2}$ . \[Hint:
With $h\left( X\right) = {aX} + b$ ,
$E\left\lbrack {h\left( X\right) }\right\rbrack = {a\mu } + b$ where
$\mu = E\left( X\right)$ .\]

42\. Suppose $E\left( X\right) = 5$ and
$E\left\lbrack {X\left( {X - 1}\right) }\right\rbrack = {27.5}$ . What
is

a\. $E\left( {X}^{2}\right)$ ? \[Hint: First verify that
$E\left\lbrack {X\left( {X - 1}\right) }\right\rbrack =$
$\left. {E\left( {X}^{2}\right) - E\left( X\right) }\right\rbrack$ ?

b\. $V\left( X\right)$ ?

c\. The general relationship among the quantities $E\left( X\right)$ ,
$E\left\lbrack {X\left( {X - 1}\right) }\right\rbrack$ , and
$V\left( X\right)$ ?

43\. Write a general rule for $E\left( {X - c}\right)$ where $c$ is a
constant. What happens when $c = \mu$ , the expected value of $X$ ?

44\. A result called Chebyshev's inequality states that for any
probability distribution of an $\mathrm{{rv}}X$ and any number $k$ that
is at least
$1,P\left( {\left| {X - \mu }\right| \geq {k\sigma }}\right) \leq 1/{k}^{2}$
. In words, the probability that the value of $X$ lies at least $k$
standard deviations from its mean is at most $1/{k}^{2}$ .

a\. What is the value of the upper bound for $k = 2$ ?
$k = 3?k = 4?k = 5?k = {10}?$

b\. Compute $\mu$ and $\sigma$ for the distribution of Exercise 13. Then
evaluate $P\left( {\left| {X - \mu }\right| \geq {k\sigma }}\right)$ for
the values of $k$ given in part (a). What does this suggest about the
upper bound relative to the corresponding probability?

c\. Let $X$ have possible values $- 1,0$ , and 1, with probabilities
$\frac{1}{18},\frac{8}{9}$ , and $\frac{1}{18}$ , respectively. What is
$P\left( {\left| {X - \mu }\right| \geq {3\sigma }}\right)$ , and how
does it compare to the corresponding bound?

d\. Give a distribution for which
$P\left( {\left| {X - \mu }\right| \geq {5\sigma }}\right) = {.04}$ .

45\. If $a \leq X \leq b$ , show that $a \leq E\left( X\right) \leq b$ .