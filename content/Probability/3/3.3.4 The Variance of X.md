- **Definition of Expected Value:**
	- The expected value $E[X]$ represents the center of the probability distribution.
- **Physical Analogy:**
	- Visualize placing point mass $p(x)$ at each value $x$ along a one-dimensional axis.
	- The axis is supported by a fulcrum positioned at $\mu$ (the expected value).
- **Equilibrium Condition:**
	- When the fulcrum is at $\mu$, the axis remains balanced, indicating no tendency to tilt.
	- This balance illustrates how $\mu$ serves as the point around which the distribution's mass is centered.
- Implications of the Analogy:
	- The expected value provides insight into the overall behavior of the distribution.
	- It highlights the concept of central tendency in probability and statistics.
- Visual Representation:
	- Figure 3.7 (not included here) likely illustrates this analogy with two different distributions, demonstrating the concept of balance at the expected value.

Figure 3.7 
Two different probability distributions with $\mu = 4$
![image](images/019165cb-e657-75f5-b964-f15ddb80567f_19_883618.jpg)

- **Comparison of Distributions:**
	- Both distributions in Figure 3.7 have the same expected value $\mu$.
    - However, the distribution shown in Figure 3.7(b) exhibits greater spread (variability or dispersion) compared to Figure 3.7(a).
  - **Role of Variance:**
    - To quantify the amount of variability in the distribution of $X$, we utilize the variance.
    - Variance, denoted as $\text{Var}(X)$ or $\sigma^2$, measures how much the values of $X$ deviate from the expected value $\mu$.
  - **Relation to Sample Variability:**
    - Just as $s^2$ (sample variance) was used in Chapter 1 to assess variability within a sample, the variance $\text{Var}(X)$ serves a similar purpose for a probability distribution.

- Implications of Variance:
	- A higher variance indicates a wider spread of values, reflecting greater uncertainty in predictions based on the distribution.
	- Understanding variance is essential for analyzing the reliability and variability of data.

- Conclusion:
	- Variance provides a crucial measure of dispersion, allowing for better insights into the behavior of random variables and their distributions.

> [!definition] variance
> - Let $X$ have $\operatorname{pmf}p\left( x\right)$ and expected value $\mu$ . 
> - Then the **variance** of $X$ , denoted by $V\left( X\right)$ or > ${\sigma }_{X}^{2}$ , or just ${\sigma }^{2}$ , is
> $$
> \begin{align}
> V\left( X\right) 
> &= \mathop{\sum }\limits_{D}{\left( x - \mu \right) }^{2} \cdot p\left( x\right) \\
> &= E\left\lbrack {\left( X - \mu \right) }^{2}\right\rbrack
> \end{align}
> $$
> 
> The **standard deviation (SD)** of $X$ is
> $${\sigma }_{X} = \sqrt{{\sigma }_{X}^{2}}$$

Squared Deviations and Variance:
- **Definition of Squared Deviation:**
	- The quantity $h(X) = (X - \mu)^2$ represents the squared deviation of $X$ from its mean $\mu$.
- **Variance:**
    - The variance $\sigma^2$ is the expected squared deviation, calculated as the weighted average of squared deviations.
    - Weights are determined by the probabilities from the distribution.
- **Impact of Probability Distribution:**
    - If most of the probability distribution is concentrated near $\mu$:
		- $\sigma^2$ will be relatively small.
    - If there are significant values of $x$ far from $\mu$ with large probabilities $p(x)$:
		- $\sigma^2$ will be quite large.
- Interpretation of Standard Deviation:
	- The standard deviation $\sigma$ can be viewed as a measure of the typical size of a deviation from the mean $\mu$.
- For example, if $\sigma = 10$:
    - In a long sequence of observed $X$ values, some will deviate from $\mu$ by more than 10, while others will be closer.
    - The typical deviation from the mean will be on the order of 10.
- Conclusion:
	- Understanding squared deviations, variance, and standard deviation is crucial for assessing variability and interpreting the behavior of random variables in statistical analysis.

[[EX 3.24 check out DVD]]

When the pmf $p\left( x\right)$ specifies a mathematical model for the distribution of population values, both ${\sigma }^{2}$ and $\sigma$ measure the spread of values in the population;
- ${\sigma }^{2}$ is the population variance, 
- $\sigma$ is the population standard deviation.